{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Approaching (Almost) Any NLP Problem\n",
    "In this post I'll talk about approaching natural language processing task. As an example, we will use the data from the spooky author identification. We will create a very basic first model first and then improve it using different other features. We will also see how deep neural networks can be used and end this post with some ideas about ensembling in general.\n",
    "\n",
    "This covers:\n",
    "tfidf\n",
    "count features\n",
    "logistic regression\n",
    "naive bayes\n",
    "svm\n",
    "xgboost\n",
    "grid search\n",
    "word vectors\n",
    "LSTM\n",
    "GRU\n",
    "Ensembling\n",
    "\n",
    "The problem requires us to predict the author, i.e. EAP, HPL and MWS given the text. In simpler words, text classification with 3 different classes.\n",
    "\n",
    "For this particular problem, Kaggle has specified multi-class log-loss as evaluation metric.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Activation, Dropout, Embedding, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection, metrics, pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/spooky-company/train.csv')\n",
    "test_data = pd.read_csv('data/spooky-company/test.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19579, 3), (8392, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Label Encode Category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category to integers from 0,1,2\n",
    "label_encoder = LabelEncoder()\n",
    "train_label = train_data.author.values\n",
    "y = label_encoder.fit_transform(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EAP', 'HPL', 'EAP', ..., 'EAP', 'EAP', 'HPL'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efea5017c88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAXD0lEQVR4nO3dfbCedX3n8fdHIqJWJUCKmMQNq1ktWkV6BvBhd1RqCLRraBcQxpaA7MSdoVZt1y12OpsW6yxOtazYlZlMiQa3BSlKybqsmAmy3VV5CEJ5lM0piiTLw5FEfECxYb/7x/07chPO4Tqh57pPHt6vmXvu6/r+ftd1/+65k3xyPaeqkCTpmTxnrgcgSdr9GRaSpE6GhSSpk2EhSepkWEiSOs2b6wH04ZBDDqklS5bM9TAkaY9y8803f6+qFkzVtleGxZIlS9i0adNcD0OS9ihJ7puuzd1QkqROhoUkqZNhIUnq1GtYJPlgkjuT3JHk0iQHJDk8yQ1JxpN8Psn+re/z2vx4a18ytJ4Pt/o9SY7vc8ySpKfrLSySLAR+FxirqtcC+wGnAR8DLqiqVwLbgbPbImcD21v9gtaPJEe05V4DLAc+nWS/vsYtSXq6vndDzQOen2Qe8ALgAeDtwBWtfR1wUpte0eZp7cclSatfVlWPV9W3gXHg6J7HLUka0ltYVNVW4OPAdxmExKPAzcD3q2pH67YFWNimFwL3t2V3tP4HD9enWObnkqxKsinJpomJidn/QpK0D+tzN9R8BlsFhwMvA17IYDdSL6pqTVWNVdXYggVTXlMiSXqW+twN9avAt6tqoqr+Efgi8GbgwLZbCmARsLVNbwUWA7T2lwCPDNenWEaSNAJ9XsH9XeDYJC8AfgIcB2wCvgqcDFwGrASuav3Xt/lvtPZrq6qSrAf+OsmfM9hCWQrcOFuD/JUPXTJbq9IzuPnPzpjrIUj6J+gtLKrqhiRXAN8EdgC3AGuA/w5cluRPW+3itsjFwOeSjAPbGJwBRVXdmeRy4K62nnOq6om+xi1Jerpe7w1VVauB1TuV72WKs5mq6qfAKdOs56PAR2d9gJKkGfEKbklSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUqfewiLJq5LcOvT6QZIPJDkoyYYkm9v7/NY/SS5MMp7ktiRHDa1rZeu/OcnKvsYsSZpab2FRVfdU1ZFVdSTwK8BjwJXAucDGqloKbGzzACcAS9trFXARQJKDGDya9RgGj2NdPRkwkqTRGNVuqOOAf6iq+4AVwLpWXwec1KZXAJfUwPXAgUkOA44HNlTVtqraDmwAlo9o3JIkRhcWpwGXtulDq+qBNv0gcGibXgjcP7TMllabrv4USVYl2ZRk08TExGyOXZL2eb2HRZL9gXcCf7NzW1UVULPxOVW1pqrGqmpswYIFs7FKSVIzii2LE4BvVtVDbf6htnuJ9v5wq28FFg8tt6jVpqtLkkZkFGFxOk/uggJYD0ye0bQSuGqofkY7K+pY4NG2u+oaYFmS+e3A9rJWkySNyLw+V57khcA7gPcOlc8HLk9yNnAfcGqrXw2cCIwzOHPqLICq2pbkI8BNrd95VbWtz3FLkp6q17Coqh8DB+9Ue4TB2VE79y3gnGnWsxZY28cYJUndvIJbktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUqdewSHJgkiuSfCvJ3UnemOSgJBuSbG7v81vfJLkwyXiS25IcNbSela3/5iQrp/9ESVIf+t6y+CTw5ap6NfB64G7gXGBjVS0FNrZ5gBOApe21CrgIIMlBwGrgGOBoYPVkwEiSRqO3Z3AneQnwr4AzAarqZ8DPkqwA3tq6rQOuA/4AWAFc0p7FfX3bKjms9d1QVdvaejcAy4FL+xq7pNF486fePNdD2Ot97X1fm5X19LllcTgwAXwmyS1J/jLJC4FDq+qB1udB4NA2vRC4f2j5La02XV2SNCJ9hsU84Cjgoqp6A/BjntzlBEDbiqjZ+LAkq5JsSrJpYmJiNlYpSWr6DIstwJaquqHNX8EgPB5qu5do7w+39q3A4qHlF7XadPWnqKo1VTVWVWMLFiyY1S8iSfu63sKiqh4E7k/yqlY6DrgLWA9MntG0EriqTa8HzmhnRR0LPNp2V10DLEsyvx3YXtZqkqQR6e0Ad/M+4K+S7A/cC5zFIKAuT3I2cB9waut7NXAiMA481vpSVduSfAS4qfU7b/JgtyRpNHoNi6q6FRiboum4KfoWcM4061kLrJ3d0UmSZsoruCVJnQwLSVInw0KS1MmwkCR16vtsKKlX3z3vl+d6CHu9l//H2+d6CNoNuGUhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSerUa1gk+U6S25PcmmRTqx2UZEOSze19fqsnyYVJxpPcluSoofWsbP03J1nZ55glSU83ii2Lt1XVkVU1+Szuc4GNVbUU2NjmAU4AlrbXKuAiGIQLsBo4BjgaWD0ZMJKk0ZiL3VArgHVteh1w0lD9khq4HjgwyWHA8cCGqtpWVduBDcDyUQ9akvZlfYdFAV9JcnOSVa12aFU90KYfBA5t0wuB+4eW3dJq09WfIsmqJJuSbJqYmJjN7yBJ+7y+n5T3lqramuQXgQ1JvjXcWFWVpGbjg6pqDbAGYGxsbFbWKUka6HXLoqq2tveHgSsZHHN4qO1eor0/3LpvBRYPLb6o1aarS5JGpLewSPLCJC+anAaWAXcA64HJM5pWAle16fXAGe2sqGOBR9vuqmuAZUnmtwPby1pNkjQife6GOhS4Msnk5/x1VX05yU3A5UnOBu4DTm39rwZOBMaBx4CzAKpqW5KPADe1fudV1bYexy1J2klvYVFV9wKvn6L+CHDcFPUCzplmXWuBtbM9RknSzHgFtySpk2EhSepkWEiSOhkWkqROhoUkqdOMwiLJxpnUJEl7p2c8dTbJAcALgEPaBXFpTS9mivszSZL2Tl3XWbwX+ADwMuBmngyLHwB/0eO4JEm7kWcMi6r6JPDJJO+rqk+NaEySpN3MjK7grqpPJXkTsGR4maq6pKdxSZJ2IzMKiySfA14B3Ao80coFGBaStA+Y6b2hxoAj2v2bJEn7mJleZ3EH8NI+ByJJ2n3NdMviEOCuJDcCj08Wq+qdvYxKkrRbmWlY/HGfg5Ak7d5mejbU/+x7IJKk3ddMz4b6IYOznwD2B54L/LiqXtzXwCRJu48ZHeCuqhdV1YtbODwf+DfAp2eybJL9ktyS5Ett/vAkNyQZT/L5JPu3+vPa/HhrXzK0jg+3+j1Jjt/F7yhJ+ifa5bvO1sDfAjP9R/v9wN1D8x8DLqiqVwLbgbNb/Wxge6tf0PqR5AjgNOA1wHLg00n229VxS5KevZnedfY3h14nJzkf+OkMllsE/Brwl20+wNuBK1qXdcBJbXpFm6e1H9f6rwAuq6rHq+rbwDhw9Iy+nSRpVsz0bKh/PTS9A/gOg3/Eu/xn4D8AL2rzBwPfr6odbX4LT969diFwP0BV7UjyaOu/ELh+aJ3Dy/xcklXAKoCXv/zlMxiaJGmmZno21Fm7uuIkvw48XFU3J3nrri6/q6pqDbAGYGxszCvNJWkWzXQ31KIkVyZ5uL2+0HYxPZM3A+9M8h3gMga7nz4JHJhkMqQWAVvb9FZgcfu8ecBLgEeG61MsI0kagZke4P4MsJ7Bcy1eBvy3VptWVX24qhZV1RIGB6ivrap3A18FTm7dVgJXten1bZ7Wfm27F9V64LR2ttThwFLgxhmOW5I0C2YaFguq6jNVtaO9PgsseJaf+QfA7yUZZ3BM4uJWvxg4uNV/DzgXoKruBC4H7gK+DJxTVU88ba2SpN7M9AD3I0l+C7i0zZ/OYBfRjFTVdcB1bfpepjibqap+CpwyzfIfBT4608+TJM2umW5ZvAc4FXgQeIDBbqIzexqTJGk3M9Mti/OAlVW1HSDJQcDHGYSIJGkvN9Mti9dNBgVAVW0D3tDPkCRJu5uZhsVzksyfnGlbFjPdKpEk7eFm+g/+J4BvJPmbNn8KHnCWpH3GTK/gviTJJgYX1gH8ZlXd1d+wJEm7kxnvSmrhYEBI0j5ol29RLkna9xgWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE69hUWSA5LcmOTvk9yZ5E9a/fAkNyQZT/L5JPu3+vPa/HhrXzK0rg+3+j1Jju9rzJKkqfW5ZfE48Paqej1wJLA8ybHAx4ALquqVwHbg7Nb/bGB7q1/Q+pHkCOA04DXAcuDTSfbrcdySpJ30FhY18KM2+9z2KgZ3rr2i1dcBJ7XpFW2e1n5ckrT6ZVX1eFV9Gxhnimd4S5L60+sxiyT7JbkVeBjYAPwD8P2q2tG6bAEWtumFwP0Arf1R4ODh+hTLDH/WqiSbkmyamJjo4+tI0j6r17Coqieq6khgEYOtgVf3+FlrqmqsqsYWLFjQ18dI0j5pJGdDVdX3ga8CbwQOTDL5HI1FwNY2vRVYDNDaXwI8MlyfYhlJ0gj0eTbUgiQHtunnA+8A7mYQGie3biuBq9r0+jZPa7+2qqrVT2tnSx0OLAVu7GvckqSnm/GT8p6Fw4B17cyl5wCXV9WXktwFXJbkT4FbgItb/4uBzyUZB7YxOAOKqrozyeUMntK3Azinqp7ocdySpJ30FhZVdRvwhinq9zLF2UxV9VPglGnW9VHgo7M9RknSzHgFtySpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqVOfz+BenOSrSe5KcmeS97f6QUk2JNnc3ue3epJcmGQ8yW1Jjhpa18rWf3OSldN9piSpH31uWewAfr+qjgCOBc5JcgRwLrCxqpYCG9s8wAnA0vZaBVwEg3ABVgPHMHgc6+rJgJEkjUZvYVFVD1TVN9v0D4G7gYXACmBd67YOOKlNrwAuqYHrgQOTHAYcD2yoqm1VtR3YACzva9ySpKcbyTGLJEuANwA3AIdW1QOt6UHg0Da9ELh/aLEtrTZdfefPWJVkU5JNExMTszp+SdrX9R4WSX4B+ALwgar6wXBbVRVQs/E5VbWmqsaqamzBggWzsUpJUtNrWCR5LoOg+Kuq+mIrP9R2L9HeH271rcDiocUXtdp0dUnSiPR5NlSAi4G7q+rPh5rWA5NnNK0Erhqqn9HOijoWeLTtrroGWJZkfjuwvazVJEkjMq/Hdb8Z+G3g9iS3ttofAucDlyc5G7gPOLW1XQ2cCIwDjwFnAVTVtiQfAW5q/c6rqm09jluStJPewqKq/jeQaZqPm6J/AedMs661wNrZG50kaVd4BbckqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKlTn8/gXpvk4SR3DNUOSrIhyeb2Pr/Vk+TCJONJbkty1NAyK1v/zUlWTvVZkqR+9bll8Vlg+U61c4GNVbUU2NjmAU4AlrbXKuAiGIQLsBo4BjgaWD0ZMJKk0ektLKrq74BtO5VXAOva9DrgpKH6JTVwPXBgksOA44ENVbWtqrYDG3h6AEmSejbqYxaHVtUDbfpB4NA2vRC4f6jfllabri5JGqE5O8BdVQXUbK0vyaokm5JsmpiYmK3VSpIYfVg81HYv0d4fbvWtwOKhfotabbr601TVmqoaq6qxBQsWzPrAJWlfNuqwWA9MntG0ErhqqH5GOyvqWODRtrvqGmBZkvntwPayVpMkjdC8vlac5FLgrcAhSbYwOKvpfODyJGcD9wGntu5XAycC48BjwFkAVbUtyUeAm1q/86pq54PmkqSe9RYWVXX6NE3HTdG3gHOmWc9aYO0sDk2StIu8gluS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkddpjwiLJ8iT3JBlPcu5cj0eS9iV7RFgk2Q/4L8AJwBHA6UmOmNtRSdK+Y48IC+BoYLyq7q2qnwGXASvmeEyStM9IVc31GDolORlYXlX/ts3/NnBMVf3OUJ9VwKo2+yrgnpEPdHQOAb4314PQs+bvt+fa23+7f1ZVC6ZqmDfqkfSlqtYAa+Z6HKOQZFNVjc31OPTs+Pvtufbl325P2Q21FVg8NL+o1SRJI7CnhMVNwNIkhyfZHzgNWD/HY5KkfcYesRuqqnYk+R3gGmA/YG1V3TnHw5pL+8Tutr2Yv9+ea5/97faIA9ySpLm1p+yGkiTNIcNCktTJsNgNJXkiya1Dr3OH2g5J8o9J/t1Oy3wnye1JbkvylSQvHf3IleRHO82fmeQv2vQfJ9naftM7krxzqP7v52K8giSV5L8Ozc9LMpHkSxn4XpL5re2w1v8tQ/0nkhyc5FVJrmu/791J9qrjG4bF7uknVXXk0Ov8obZTgOuB06dY7m1V9TpgE/CHoxiodtkFVXUkg99xbRL/Ds69HwOvTfL8Nv8O2qn5NTioez3wxtb2JuCW9k6SVwGPVNUjwIW037eqfgn41Oi+Qv/8g7rnOR34fWBhkkXT9Pk74JWjG5J2VVXdDexgcEWw5t7VwK+16dOBS4favk4Lh/Z+AU8Nj6+16cOALZMLVdXtfQ12LhgWu6fn77Qb6l0ASRYDh1XVjcDlwLumWf7Xgb3qD+oe5Cm/HXDeVJ2SHAP8P2BipKPTdC4DTktyAPA64Iahtq/xZFgcDVzJkxcJv4lBmMAgRK5N8j+SfDDJgf0Pe3T2iOss9kE/absqdvYuBiEBgz/ca4FPDLV/NckTwG3AH/U7RE3jKb9dkjOB4dtDfDDJbwE/BN5VVZVkxEPUzqrqtiRLGGxVXL1T803AG5K8EHhuVf0oyb1JXskgLD7R1vGZJNcAyxnc6PS9SV5fVY+P6nv0ybDYs5wOvDTJu9v8y5IsrarNbf5tVbU33+Rsb3BBVX18rgehKa0HPg68FTh4slhVjyXZDLwH+GYrXw+cCPwiQzctrar/y+A/cWuT3AG8Frh5FIPvm7uh9hBJ/gXwC1W1sKqWVNUS4D8x9YFuSbtuLfAn0xxr+DrwAeAbbf4bwPuB69tB8MkHtD23Tb+UQeDsNfewMyx2TzsfszifQShcuVO/L2BY7C3+KMmWyddcD2ZfVFVbqurCaZq/BvxzngyLbzK4oenXh/osA+5I8vcMbk30oap6sK/xjpq3+5AkdXLLQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkHqW5KQkRwzNX5dk7JmWkXY3hoXUv5OAIzp7zUAS77qgOWFYSM9Ckr9NcnOSO5OsarUfDbWfnOSzSd4EvBP4s3aB5Stal1OS3Jjk/yT5l22ZA5J8pj2X5JYkb2v1M5OsT3ItsHG031Qa8H8p0rPznqra1p6BcFOSL0zVqaq+nmQ98KWqugKg3ThwXlUdneREYDXwq8A5g0Xql5O8GvhKu80LwFHA66pqW8/fS5qSYSE9O7+b5Dfa9GJg6S4u/8X2fjOwpE2/hfbAnKr6VpL7gMmw2GBQaC4ZFtIuSvJWBlsCb2x3JL0OOAAYvnfOAR2rmbxt9RPM7O/hj3dxmNKs8piFtOteAmxvQfFq4NhWfyjJL7VHpf7GUP8fAi+awXr/F/Bu+Pldhl/O0O2vpblkWEi77svAvCR3A+czeLYBwLnAlxjcifSBof6XAR9qB61fwfQ+DTwnye3A54Ez95YH52jP511nJUmd3LKQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSp/8PoRuYDbQ7uw0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='author', data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    7900\n",
       "MWS    6044\n",
       "HPL    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'author'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-0304586f4a9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'author'"
     ]
    }
   ],
   "source": [
    "test_data.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.text.values\n",
    "y_test = test_data.aut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y, \n",
    "                                                      random_state=42, \n",
    "                                                      test_size=0.1,\n",
    "                                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17621,), (1958,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, y_train, y_valid = train_test_split(X, y, stratify=y, \n",
    "                                                      random_state=42, \n",
    "                                                      test_size=0.1,\n",
    "                                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise(vector, X_train, X_valid):\n",
    "    # Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "    vector.fit(list(X_train) + list(X_valid))\n",
    "    xtrain_vec =  vector.transform(X_train) \n",
    "    xvalid_vec = vector.transform(X_valid)\n",
    "    return xtrain_vec, xvalid_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(xtrain_vec, xvalid_vec, y_train, clf):\n",
    "    # Fitting a simple Logistic Regression on TFIDF\n",
    "    clf.fit(xtrain_vec, y_train)\n",
    "    predictions = clf.predict_proba(xvalid_vec)\n",
    "    print(\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TFIDF\n",
    "tfidf = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CV\n",
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tfidf,v_tfidf = vectorise(tfidf,X_train, X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ctv,v_ctv = vectorise(ctv,X_train, X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.572 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF\n",
    "train_predict(x_tfidf,v_tfidf,y_train, clf)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "And there we go. We have our first model \n",
    "with a multiclass logloss of 0.626.\n",
    "\n",
    "But we are greedy and want a better score. \n",
    "Lets look at the same model with a different data.\n",
    "\n",
    "Instead of using TF-IDF, we can also use word counts as features. \n",
    "This can be done easily using CountVectorizer from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.527 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# CV\n",
    "train_predict(x_ctv,v_ctv,y_train, clf)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Our model was improved using Count vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Using Naive base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.578 \n"
     ]
    }
   ],
   "source": [
    "# TFIDF\n",
    "train_predict(x_tfidf,v_tfidf,y_train, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.485 \n"
     ]
    }
   ],
   "source": [
    "# CV\n",
    "train_predict(x_ctv,v_ctv,y_train, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB does better with the CV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for svm we have to Apply SVD, I chose 120 components. \n",
    "# 120-200 components are good enough for SVM model.\n",
    "\n",
    "svd = TruncatedSVD(n_components=120)\n",
    "svd.fit(x_tfidf)\n",
    "xtrain_svd = svd.transform(x_tfidf)\n",
    "xvalid_svd = svd.transform(v_tfidf)\n",
    "\n",
    "# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\n",
    "scl = StandardScaler()\n",
    "scl.fit(xtrain_svd)\n",
    "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
    "xvalid_svd_scl = scl.transform(xvalid_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=1.0, probability=True) # since we need probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.732 \n"
     ]
    }
   ],
   "source": [
    "train_predict(xtrain_svd_scl, xvalid_svd_scl, y_train, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC doesnt do well on this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.782 \n"
     ]
    }
   ],
   "source": [
    "# TFIDF\n",
    "train_predict(x_tfidf,v_tfidf,y_train, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.773 \n"
     ]
    }
   ],
   "source": [
    "# CV\n",
    "train_predict(x_ctv,v_ctv,y_train, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB also not doing well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Grid Search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "its a technique for hyperparameter optimization. \n",
    "Not so effective but can give good results \n",
    "if you know the grid you want to use. \n",
    "I specify the parameters that should usually be used in this post: \n",
    "http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/ Please keep in mind that these are the parameters I usually use. There are many other methods of hyperparameter optimization which may or may not be as effective.\n",
    "\n",
    "In this section, I'll talk about grid search using logistic regression.\n",
    "\n",
    "Before starting with grid search we need to create a scoring function. \n",
    "This is accomplished using the make_scorer function of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mll_scorer = metrics.make_scorer(multiclass_logloss, \n",
    "                                 greater_is_better=False, \n",
    "                                 needs_proba=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next we need a pipeline. For demonstration here, \n",
    "i'll be using a pipeline consisting of SVD, scaling and then logistic regression\n",
    "Its better to understand with more modules in pipeline than just one ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVD\n",
    "svd = TruncatedSVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the standard scaler \n",
    "scl = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use logistic regression here..\n",
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('svd', svd),\n",
    "                         ('scl', scl),\n",
    "                         ('lr', lr_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'svd__n_components' : [120, 180],\n",
    "              'lr__C': [0.1, 1.0, 10], \n",
    "              'lr__penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "So, for SVD we evaluate 120 and 180 components \n",
    "and for logistic regression we evaluate three different values of C \n",
    "with l1 and l2 penalty. We can now start grid search on these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, \n",
    "                     scoring=mll_scorer,verbose=10, n_jobs=-1, \n",
    "                     iid=True, refit=True, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  24 | elapsed:   11.8s remaining:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  24 | elapsed:   13.0s remaining:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  24 | elapsed:   16.3s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  24 | elapsed:   17.4s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   18.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   18.1s finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('svd',\n",
       "                                        TruncatedSVD(algorithm='randomized',\n",
       "                                                     n_components=2, n_iter=5,\n",
       "                                                     random_state=None,\n",
       "                                                     tol=0.0)),\n",
       "                                       ('scl',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(C=1.0,\n",
       "                                                           class_weight=None,\n",
       "                                                           dual=False,\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_ite...\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'lr__C': [0.1, 1.0, 10], 'lr__penalty': ['l1', 'l2'],\n",
       "                         'svd__n_components': [120, 180]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True),\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Grid Search Model\n",
    "model.fit(x_tfidf, y_train)  \n",
    "# we can use the full data here but im only using xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.738\n",
      "Best parameters set:\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "\tlr__C: 10\n",
      "\tlr__penalty: 'l2'\n",
      "\tsvd__n_components: 180\n"
     ]
    }
   ],
   "source": [
    "best_parameters = model.best_estimator_.get_params()\n",
    "print(\"Best parameters set:\")\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The score comes similar to what we had for SVM. \n",
    "This technique can be used to finetune xgboost \n",
    "or even multinomial naive bayes as below. \n",
    "We will use the tfidf data here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "Best score: -0.492\n",
      "Best parameters set:\n",
      "\tnb__alpha: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0217s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.1s finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('nb', nb_model)])\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
    "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(x_tfidf, y_train)  # we can use the full data here but im only using xtrain. \n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is an improvement of 8% over the original naive bayes score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Word Vectors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Without going into too much details, \n",
    "I would explain how to create sentence vectors \n",
    "and how can we use them to create a machine learning model on top of it. \n",
    "I am a fan of GloVe vectors, word2vec and fasttext. \n",
    "In this post, I'll be using the GloVe vectors. \n",
    "You can download the GloVe vectors from here \n",
    "http://www-nlp.stanford.edu/data/glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the GloVe vectors in a dictionary: \n",
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    with open(gloveFile,'r', encoding='utf8') as f:\n",
    "        embeddings = {}\n",
    "        for line in f:\n",
    "            splitLine = line.split()\n",
    "            word = splitLine[0]\n",
    "            embedding = np.asarray(splitLine[1:], dtype='float32')\n",
    "            embeddings[word] = embedding\n",
    "    print(\"Done.\",len(embeddings),\" words loaded!\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 1917495  words loaded!\n"
     ]
    }
   ],
   "source": [
    "glove_embeddings = loadGloveModel('pretrained-models/glove.42B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('glove.6B.300d.pkl', 'wb') as fp:\n",
    "    pickle.dump(glove_embeddings, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates a normalized vector for the whole sentence\n",
    "def sent2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(glove_embeddings[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17621/17621 [00:11<00:00, 1469.07it/s]\n",
      "100%|██████████| 1958/1958 [00:00<00:00, 3212.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# create sentence vectors using the above function for training and validation set\n",
    "xtrain_glove = [sent2vec(x) for x in tqdm(X_train)]\n",
    "xvalid_glove = [sent2vec(x) for x in tqdm(X_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_glove = np.array(xtrain_glove)\n",
    "xvalid_glove = np.array(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost on Glove\n",
    "# Fitting a simple xgboost on glove features\n",
    "clf = XGBClassifier(nthread=10, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.749 \n"
     ]
    }
   ],
   "source": [
    "train_predict(xtrain_glove,xvalid_glove,y_train, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuining parameters\n",
    "clf = XGBClassifier(max_depth=7, n_estimators=200, \n",
    "                        colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, \n",
    "                        learning_rate=0.1, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.726 \n"
     ]
    }
   ],
   "source": [
    "train_predict(xtrain_glove,xvalid_glove,y_train, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see a slight improvement after tuining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Deep Learning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here, we will train LSTM and a simple dense network on the GloVe features.\n",
    "Let's start with the dense network first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data before any neural net:\n",
    "scl = StandardScaler()\n",
    "xtrain_glove_scl = scl.fit_transform(xtrain_glove)\n",
    "xvalid_glove_scl = scl.transform(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to binarize the labels for the neural net\n",
    "ytrain_enc = to_categorical(y_train)\n",
    "yvalid_enc = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ytrain_enc)\n",
    "ytrain_enc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple 3 layer sequential neural net\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(300, input_dim=300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/5\n",
      "17621/17621 [==============================] - 4s 199us/sample - loss: 0.9412 - val_loss: 0.7419\n",
      "Epoch 2/5\n",
      "17621/17621 [==============================] - 1s 66us/sample - loss: 0.7242 - val_loss: 0.7132\n",
      "Epoch 3/5\n",
      "17621/17621 [==============================] - 1s 67us/sample - loss: 0.6565 - val_loss: 0.6966\n",
      "Epoch 4/5\n",
      "17621/17621 [==============================] - 2s 124us/sample - loss: 0.6067 - val_loss: 0.6854\n",
      "Epoch 5/5\n",
      "17621/17621 [==============================] - 1s 67us/sample - loss: 0.5808 - val_loss: 0.6854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efe87d28438>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_glove_scl, y=ytrain_enc, batch_size=64, \n",
    "          epochs=5, verbose=1, \n",
    "          validation_data=(xvalid_glove_scl, yvalid_enc))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You need to keep on tuning the parameters of the neural network, \n",
    "add more layers, increase dropout to get better results. \n",
    "Here, I'm just showing that its fast to implement and run \n",
    "and gets better result than xgboost without any optimization :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LSTMs we need to tokenize the text data\n",
    "# using keras tokenizer here\n",
    "token = Tokenizer(num_words=None)\n",
    "max_len = 70\n",
    "\n",
    "token.fit_on_texts(list(X_train) + list(X_valid))\n",
    "xtrain_seq = token.texts_to_sequences(X_train)\n",
    "xvalid_seq = token.texts_to_sequences(X_valid)\n",
    "xtest_seq = token.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero pad the sequences\n",
    "xtrain_pad = pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,    13,     8,    36,   329,   876,     4,\n",
       "           1,   379,    82,    37,    88,  3278,  1730,     2,   778,\n",
       "           9, 10108,    66,   196,    48,   587,    25,  2678,   118,\n",
       "          76,    24,    48,   112, 16050,     2,  3939], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_pad[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'and': 3,\n",
       " 'to': 4,\n",
       " 'a': 5,\n",
       " 'i': 6,\n",
       " 'in': 7,\n",
       " 'was': 8,\n",
       " 'that': 9,\n",
       " 'my': 10,\n",
       " 'it': 11,\n",
       " 'had': 12,\n",
       " 'he': 13,\n",
       " 'with': 14,\n",
       " 'his': 15,\n",
       " 'as': 16,\n",
       " 'for': 17,\n",
       " 'which': 18,\n",
       " 'but': 19,\n",
       " 'not': 20,\n",
       " 'at': 21,\n",
       " 'me': 22,\n",
       " 'from': 23,\n",
       " 'by': 24,\n",
       " 'is': 25,\n",
       " 'this': 26,\n",
       " 'on': 27,\n",
       " 'be': 28,\n",
       " 'her': 29,\n",
       " 'were': 30,\n",
       " 'have': 31,\n",
       " 'all': 32,\n",
       " 'you': 33,\n",
       " 'we': 34,\n",
       " 'or': 35,\n",
       " 'no': 36,\n",
       " 'an': 37,\n",
       " 'one': 38,\n",
       " 'so': 39,\n",
       " 'him': 40,\n",
       " 'when': 41,\n",
       " 'been': 42,\n",
       " 'they': 43,\n",
       " 'upon': 44,\n",
       " 'there': 45,\n",
       " 'could': 46,\n",
       " 'she': 47,\n",
       " 'its': 48,\n",
       " 'would': 49,\n",
       " 'more': 50,\n",
       " 'now': 51,\n",
       " 'their': 52,\n",
       " 'what': 53,\n",
       " 'some': 54,\n",
       " 'our': 55,\n",
       " 'are': 56,\n",
       " 'into': 57,\n",
       " 'than': 58,\n",
       " 'will': 59,\n",
       " 'very': 60,\n",
       " 'who': 61,\n",
       " 'if': 62,\n",
       " 'them': 63,\n",
       " 'only': 64,\n",
       " 'then': 65,\n",
       " 'up': 66,\n",
       " 'these': 67,\n",
       " 'before': 68,\n",
       " 'about': 69,\n",
       " 'any': 70,\n",
       " 'man': 71,\n",
       " 'time': 72,\n",
       " 'yet': 73,\n",
       " 'out': 74,\n",
       " 'said': 75,\n",
       " 'even': 76,\n",
       " 'did': 77,\n",
       " 'your': 78,\n",
       " 'might': 79,\n",
       " 'after': 80,\n",
       " 'old': 81,\n",
       " 'like': 82,\n",
       " 'first': 83,\n",
       " 'us': 84,\n",
       " 'must': 85,\n",
       " 'most': 86,\n",
       " 'through': 87,\n",
       " 'over': 88,\n",
       " 'never': 89,\n",
       " 'made': 90,\n",
       " 'life': 91,\n",
       " 'night': 92,\n",
       " 'found': 93,\n",
       " 'such': 94,\n",
       " 'other': 95,\n",
       " 'should': 96,\n",
       " 'do': 97,\n",
       " 'seemed': 98,\n",
       " 'eyes': 99,\n",
       " 'every': 100,\n",
       " 'little': 101,\n",
       " 'while': 102,\n",
       " 'still': 103,\n",
       " 'those': 104,\n",
       " 'myself': 105,\n",
       " 'day': 106,\n",
       " 'great': 107,\n",
       " 'long': 108,\n",
       " 'saw': 109,\n",
       " 'has': 110,\n",
       " 'where': 111,\n",
       " 'own': 112,\n",
       " 'many': 113,\n",
       " 'well': 114,\n",
       " 'again': 115,\n",
       " 'came': 116,\n",
       " 'much': 117,\n",
       " 'down': 118,\n",
       " 'may': 119,\n",
       " 'thought': 120,\n",
       " 'how': 121,\n",
       " 'two': 122,\n",
       " 'being': 123,\n",
       " 'can': 124,\n",
       " 'once': 125,\n",
       " 'see': 126,\n",
       " 'say': 127,\n",
       " 'here': 128,\n",
       " 'ever': 129,\n",
       " 'thus': 130,\n",
       " 'whose': 131,\n",
       " 'am': 132,\n",
       " 'death': 133,\n",
       " 'mind': 134,\n",
       " 'without': 135,\n",
       " 'far': 136,\n",
       " 'too': 137,\n",
       " 'heart': 138,\n",
       " 'things': 139,\n",
       " 'shall': 140,\n",
       " 'house': 141,\n",
       " 'heard': 142,\n",
       " 'however': 143,\n",
       " 'left': 144,\n",
       " 'thing': 145,\n",
       " 'men': 146,\n",
       " 'years': 147,\n",
       " 'felt': 148,\n",
       " 'place': 149,\n",
       " 'last': 150,\n",
       " 'know': 151,\n",
       " 'love': 152,\n",
       " 'himself': 153,\n",
       " 'light': 154,\n",
       " 'though': 155,\n",
       " 'few': 156,\n",
       " 'indeed': 157,\n",
       " 'come': 158,\n",
       " 'world': 159,\n",
       " 'earth': 160,\n",
       " 'room': 161,\n",
       " 'way': 162,\n",
       " 'door': 163,\n",
       " 'back': 164,\n",
       " 'within': 165,\n",
       " 'head': 166,\n",
       " 'nothing': 167,\n",
       " 'whole': 168,\n",
       " 'having': 169,\n",
       " 'became': 170,\n",
       " 'let': 171,\n",
       " 'away': 172,\n",
       " 'words': 173,\n",
       " 'hand': 174,\n",
       " 'each': 175,\n",
       " 'nor': 176,\n",
       " 'strange': 177,\n",
       " 'seen': 178,\n",
       " 'same': 179,\n",
       " 'make': 180,\n",
       " 'among': 181,\n",
       " 'nature': 182,\n",
       " 'under': 183,\n",
       " 'length': 184,\n",
       " \"'\": 185,\n",
       " 'human': 186,\n",
       " 'good': 187,\n",
       " 'knew': 188,\n",
       " 'voice': 189,\n",
       " 'friend': 190,\n",
       " 'soon': 191,\n",
       " 'three': 192,\n",
       " 'new': 193,\n",
       " 'half': 194,\n",
       " 'during': 195,\n",
       " 'beyond': 196,\n",
       " 'part': 197,\n",
       " 'although': 198,\n",
       " 'moment': 199,\n",
       " 'alone': 200,\n",
       " 'raymond': 201,\n",
       " 'less': 202,\n",
       " 'another': 203,\n",
       " 'off': 204,\n",
       " 'sea': 205,\n",
       " 'since': 206,\n",
       " 'air': 207,\n",
       " 'fear': 208,\n",
       " 'just': 209,\n",
       " 'gave': 210,\n",
       " 'almost': 211,\n",
       " 'looked': 212,\n",
       " 'small': 213,\n",
       " 'father': 214,\n",
       " 'young': 215,\n",
       " 'around': 216,\n",
       " 'above': 217,\n",
       " 'took': 218,\n",
       " 'near': 219,\n",
       " 'full': 220,\n",
       " 'soul': 221,\n",
       " 'body': 222,\n",
       " 'find': 223,\n",
       " 'city': 224,\n",
       " 'dark': 225,\n",
       " 'something': 226,\n",
       " 'whom': 227,\n",
       " 'certain': 228,\n",
       " 'passed': 229,\n",
       " 'went': 230,\n",
       " 'told': 231,\n",
       " 'days': 232,\n",
       " 'lay': 233,\n",
       " 'appeared': 234,\n",
       " 'why': 235,\n",
       " 'course': 236,\n",
       " 'face': 237,\n",
       " 'end': 238,\n",
       " 'think': 239,\n",
       " 'also': 240,\n",
       " 'take': 241,\n",
       " 'mr': 242,\n",
       " 'high': 243,\n",
       " 'itself': 244,\n",
       " 'perhaps': 245,\n",
       " 'dead': 246,\n",
       " 'open': 247,\n",
       " 'spirit': 248,\n",
       " 'point': 249,\n",
       " 'until': 250,\n",
       " 'horror': 251,\n",
       " 'black': 252,\n",
       " \"an'\": 253,\n",
       " 'between': 254,\n",
       " 'idea': 255,\n",
       " 'hope': 256,\n",
       " 'water': 257,\n",
       " 'deep': 258,\n",
       " 'go': 259,\n",
       " 'feet': 260,\n",
       " 'tell': 261,\n",
       " 'form': 262,\n",
       " 'matter': 263,\n",
       " 'began': 264,\n",
       " 'known': 265,\n",
       " 'right': 266,\n",
       " 'kind': 267,\n",
       " 'name': 268,\n",
       " 'least': 269,\n",
       " 'cannot': 270,\n",
       " 'lost': 271,\n",
       " 'turned': 272,\n",
       " 'look': 273,\n",
       " 'often': 274,\n",
       " 'street': 275,\n",
       " 'rather': 276,\n",
       " 'side': 277,\n",
       " 'manner': 278,\n",
       " 'because': 279,\n",
       " 'called': 280,\n",
       " 'against': 281,\n",
       " 'morning': 282,\n",
       " 'moon': 283,\n",
       " 'hours': 284,\n",
       " 'become': 285,\n",
       " 'towards': 286,\n",
       " 'brought': 287,\n",
       " 'present': 288,\n",
       " 'sometimes': 289,\n",
       " 'home': 290,\n",
       " 'scene': 291,\n",
       " 'power': 292,\n",
       " 'always': 293,\n",
       " 'nearly': 294,\n",
       " 'taken': 295,\n",
       " 'means': 296,\n",
       " 'return': 297,\n",
       " 'sun': 298,\n",
       " 'eye': 299,\n",
       " 'sound': 300,\n",
       " 'object': 301,\n",
       " 'feel': 302,\n",
       " 'both': 303,\n",
       " 'stood': 304,\n",
       " 'people': 305,\n",
       " 'spoke': 306,\n",
       " 'thousand': 307,\n",
       " 'sight': 308,\n",
       " 'hour': 309,\n",
       " 'ancient': 310,\n",
       " 'put': 311,\n",
       " 'person': 312,\n",
       " 'fact': 313,\n",
       " 'hands': 314,\n",
       " 'doubt': 315,\n",
       " 'country': 316,\n",
       " 'fell': 317,\n",
       " 'wild': 318,\n",
       " 'several': 319,\n",
       " 'large': 320,\n",
       " 'perdita': 321,\n",
       " 'general': 322,\n",
       " 'town': 323,\n",
       " 'true': 324,\n",
       " 'beauty': 325,\n",
       " 'set': 326,\n",
       " 'de': 327,\n",
       " 'second': 328,\n",
       " 'longer': 329,\n",
       " 'suddenly': 330,\n",
       " 'better': 331,\n",
       " 'state': 332,\n",
       " 'dreams': 333,\n",
       " 'give': 334,\n",
       " 'speak': 335,\n",
       " 'grew': 336,\n",
       " 'terrible': 337,\n",
       " 'white': 338,\n",
       " 'continued': 339,\n",
       " 'entered': 340,\n",
       " 'done': 341,\n",
       " 'dream': 342,\n",
       " 'reason': 343,\n",
       " 'work': 344,\n",
       " 'believe': 345,\n",
       " 'possible': 346,\n",
       " 'sleep': 347,\n",
       " 'others': 348,\n",
       " 'already': 349,\n",
       " 'beneath': 350,\n",
       " 'truth': 351,\n",
       " 'quite': 352,\n",
       " 'toward': 353,\n",
       " 'times': 354,\n",
       " 'remained': 355,\n",
       " 'floor': 356,\n",
       " 'poor': 357,\n",
       " 'attention': 358,\n",
       " 'family': 359,\n",
       " 'word': 360,\n",
       " 'sense': 361,\n",
       " 'change': 362,\n",
       " 'period': 363,\n",
       " 'case': 364,\n",
       " 'themselves': 365,\n",
       " 'wind': 366,\n",
       " 'thoughts': 367,\n",
       " 'trees': 368,\n",
       " 'dear': 369,\n",
       " 'past': 370,\n",
       " 'looking': 371,\n",
       " 'west': 372,\n",
       " 'till': 373,\n",
       " 'close': 374,\n",
       " 'read': 375,\n",
       " 'low': 376,\n",
       " 'despair': 377,\n",
       " 'appearance': 378,\n",
       " 'ground': 379,\n",
       " 'window': 380,\n",
       " 'view': 381,\n",
       " 'character': 382,\n",
       " 'either': 383,\n",
       " 'next': 384,\n",
       " 'countenance': 385,\n",
       " 'god': 386,\n",
       " 'none': 387,\n",
       " 'vast': 388,\n",
       " 'five': 389,\n",
       " 'given': 390,\n",
       " 'died': 391,\n",
       " 'oh': 392,\n",
       " 'stone': 393,\n",
       " 'evil': 394,\n",
       " 'tears': 395,\n",
       " 'adrian': 396,\n",
       " 'unknown': 397,\n",
       " 'account': 398,\n",
       " 'together': 399,\n",
       " 'question': 400,\n",
       " 'walls': 401,\n",
       " 'evening': 402,\n",
       " 'mother': 403,\n",
       " 'enough': 404,\n",
       " 'best': 405,\n",
       " 'led': 406,\n",
       " 'sat': 407,\n",
       " 'gone': 408,\n",
       " 'rest': 409,\n",
       " 'child': 410,\n",
       " 'happiness': 411,\n",
       " 'immediately': 412,\n",
       " 'interest': 413,\n",
       " 'replied': 414,\n",
       " 'returned': 415,\n",
       " 'happy': 416,\n",
       " 'space': 417,\n",
       " 'hideous': 418,\n",
       " 'sure': 419,\n",
       " 'land': 420,\n",
       " 'therefore': 421,\n",
       " 'mere': 422,\n",
       " 'age': 423,\n",
       " 'blood': 424,\n",
       " 'existence': 425,\n",
       " 'get': 426,\n",
       " 'behind': 427,\n",
       " 'chamber': 428,\n",
       " 'feelings': 429,\n",
       " 'feeling': 430,\n",
       " 'wall': 431,\n",
       " 'natural': 432,\n",
       " 'held': 433,\n",
       " 'four': 434,\n",
       " 'merely': 435,\n",
       " 'reached': 436,\n",
       " 'cold': 437,\n",
       " 'latter': 438,\n",
       " 'gentle': 439,\n",
       " 'england': 440,\n",
       " 'expression': 441,\n",
       " 'sky': 442,\n",
       " 'discovered': 443,\n",
       " 'wish': 444,\n",
       " 'short': 445,\n",
       " 'filled': 446,\n",
       " 'fellow': 447,\n",
       " 'memory': 448,\n",
       " 'knowledge': 449,\n",
       " 'friends': 450,\n",
       " 'call': 451,\n",
       " 'wonder': 452,\n",
       " 'observed': 453,\n",
       " 'idris': 454,\n",
       " 'secret': 455,\n",
       " 'leave': 456,\n",
       " 'fire': 457,\n",
       " 'neither': 458,\n",
       " 'living': 459,\n",
       " 'windows': 460,\n",
       " 'river': 461,\n",
       " 'imagination': 462,\n",
       " 'terror': 463,\n",
       " 'forth': 464,\n",
       " 'altogether': 465,\n",
       " 'late': 466,\n",
       " 'portion': 467,\n",
       " 'hear': 468,\n",
       " 'misery': 469,\n",
       " 'below': 470,\n",
       " 'distance': 471,\n",
       " 'followed': 472,\n",
       " 'herself': 473,\n",
       " 'heaven': 474,\n",
       " 'children': 475,\n",
       " 'circumstances': 476,\n",
       " 'self': 477,\n",
       " 'die': 478,\n",
       " 'care': 479,\n",
       " 'greater': 480,\n",
       " 'cause': 481,\n",
       " 'lips': 482,\n",
       " 'subject': 483,\n",
       " 'arms': 484,\n",
       " 'purpose': 485,\n",
       " 'silence': 486,\n",
       " 'joy': 487,\n",
       " 'difficulty': 488,\n",
       " 'lady': 489,\n",
       " 'green': 490,\n",
       " 'peculiar': 491,\n",
       " 'remember': 492,\n",
       " 'degree': 493,\n",
       " 'months': 494,\n",
       " 'letter': 495,\n",
       " 'along': 496,\n",
       " 'formed': 497,\n",
       " 'really': 498,\n",
       " 'necessary': 499,\n",
       " 'spot': 500,\n",
       " 'loved': 501,\n",
       " \"o'\": 502,\n",
       " 'impossible': 503,\n",
       " 'houses': 504,\n",
       " 'scarcely': 505,\n",
       " 'corpse': 506,\n",
       " 'arm': 507,\n",
       " 'youth': 508,\n",
       " 'shadow': 509,\n",
       " 'sir': 510,\n",
       " 'bed': 511,\n",
       " 'grave': 512,\n",
       " 'opened': 513,\n",
       " 'sought': 514,\n",
       " 'use': 515,\n",
       " 'table': 516,\n",
       " 'steps': 517,\n",
       " 'usual': 518,\n",
       " 'mine': 519,\n",
       " 'year': 520,\n",
       " 'darkness': 521,\n",
       " 'm': 522,\n",
       " 'mad': 523,\n",
       " 'save': 524,\n",
       " 'finally': 525,\n",
       " 'wide': 526,\n",
       " 'received': 527,\n",
       " 'mountain': 528,\n",
       " 'live': 529,\n",
       " 'beautiful': 530,\n",
       " 'line': 531,\n",
       " 'common': 532,\n",
       " 'arose': 533,\n",
       " 'somewhat': 534,\n",
       " 'sweet': 535,\n",
       " 'entirely': 536,\n",
       " 'early': 537,\n",
       " 'heavy': 538,\n",
       " 'possessed': 539,\n",
       " 'cast': 540,\n",
       " 'grief': 541,\n",
       " 'twenty': 542,\n",
       " 'six': 543,\n",
       " 'kept': 544,\n",
       " 'placed': 545,\n",
       " 'order': 546,\n",
       " 'ill': 547,\n",
       " 'lived': 548,\n",
       " 'ye': 549,\n",
       " 'boat': 550,\n",
       " 'across': 551,\n",
       " 'met': 552,\n",
       " 'ten': 553,\n",
       " 'figure': 554,\n",
       " 'especially': 555,\n",
       " 'rose': 556,\n",
       " 'affection': 557,\n",
       " 'distant': 558,\n",
       " 'beheld': 559,\n",
       " 'hair': 560,\n",
       " 'woman': 561,\n",
       " 'resolved': 562,\n",
       " 'box': 563,\n",
       " 'hill': 564,\n",
       " 'dr': 565,\n",
       " 'north': 566,\n",
       " 'round': 567,\n",
       " 'effect': 568,\n",
       " 'london': 569,\n",
       " 'single': 570,\n",
       " 'odd': 571,\n",
       " 'pleasure': 572,\n",
       " 'paper': 573,\n",
       " 'fully': 574,\n",
       " 'various': 575,\n",
       " 'visible': 576,\n",
       " 'thrown': 577,\n",
       " 'position': 578,\n",
       " 'book': 579,\n",
       " 'wife': 580,\n",
       " 'coming': 581,\n",
       " 'whether': 582,\n",
       " 'presence': 583,\n",
       " 'proceeded': 584,\n",
       " 'surface': 585,\n",
       " 'escape': 586,\n",
       " 'strength': 587,\n",
       " 'does': 588,\n",
       " 'singular': 589,\n",
       " 'fancy': 590,\n",
       " 'atmosphere': 591,\n",
       " 'books': 592,\n",
       " 'hold': 593,\n",
       " 'instant': 594,\n",
       " 'born': 595,\n",
       " 'force': 596,\n",
       " 'plague': 597,\n",
       " 'ordinary': 598,\n",
       " 'lovely': 599,\n",
       " 'later': 600,\n",
       " 'thou': 601,\n",
       " 'asked': 602,\n",
       " 'hills': 603,\n",
       " 'former': 604,\n",
       " 'horrible': 605,\n",
       " 'minutes': 606,\n",
       " 'streets': 607,\n",
       " 'delight': 608,\n",
       " 'caused': 609,\n",
       " 'cottage': 610,\n",
       " 'apparently': 611,\n",
       " 'sounds': 612,\n",
       " 'turn': 613,\n",
       " 'hundred': 614,\n",
       " 'o': 615,\n",
       " 'influence': 616,\n",
       " 'anything': 617,\n",
       " 'direction': 618,\n",
       " 'red': 619,\n",
       " 'sorrow': 620,\n",
       " 'beloved': 621,\n",
       " 'clear': 622,\n",
       " 'pain': 623,\n",
       " 'tried': 624,\n",
       " 'arrived': 625,\n",
       " 'changed': 626,\n",
       " 'silent': 627,\n",
       " 'easily': 628,\n",
       " 'fate': 629,\n",
       " 'slight': 630,\n",
       " 'party': 631,\n",
       " 'closed': 632,\n",
       " 'got': 633,\n",
       " 'ago': 634,\n",
       " 'girl': 635,\n",
       " 'hopes': 636,\n",
       " 'says': 637,\n",
       " 'desire': 638,\n",
       " 'main': 639,\n",
       " 'simple': 640,\n",
       " 'cut': 641,\n",
       " 'understand': 642,\n",
       " 'excited': 643,\n",
       " 'calm': 644,\n",
       " 'yes': 645,\n",
       " 'events': 646,\n",
       " 'lord': 647,\n",
       " 'narrow': 648,\n",
       " 'tale': 649,\n",
       " 'public': 650,\n",
       " 'balloon': 651,\n",
       " 'sister': 652,\n",
       " 'east': 653,\n",
       " 'business': 654,\n",
       " 'madame': 655,\n",
       " 'blue': 656,\n",
       " 'broken': 657,\n",
       " 'struck': 658,\n",
       " 'miserable': 659,\n",
       " 'motion': 660,\n",
       " 'apparent': 661,\n",
       " 'threw': 662,\n",
       " 'stars': 663,\n",
       " 'drew': 664,\n",
       " 'companion': 665,\n",
       " 'bring': 666,\n",
       " 'fallen': 667,\n",
       " 'regard': 668,\n",
       " 'art': 669,\n",
       " 'society': 670,\n",
       " 'forgotten': 671,\n",
       " 'real': 672,\n",
       " 'south': 673,\n",
       " 'making': 674,\n",
       " 'valley': 675,\n",
       " 'going': 676,\n",
       " 'top': 677,\n",
       " 'road': 678,\n",
       " 'alas': 679,\n",
       " 'company': 680,\n",
       " 'keep': 681,\n",
       " 'future': 682,\n",
       " 'faint': 683,\n",
       " 'thy': 684,\n",
       " 'passion': 685,\n",
       " 'utterly': 686,\n",
       " 'uncle': 687,\n",
       " 'perceived': 688,\n",
       " 'visit': 689,\n",
       " 'third': 690,\n",
       " 'wished': 691,\n",
       " 'else': 692,\n",
       " 'design': 693,\n",
       " 'frame': 694,\n",
       " 'mean': 695,\n",
       " 'ears': 696,\n",
       " 'vain': 697,\n",
       " 'bore': 698,\n",
       " 'entire': 699,\n",
       " 'ship': 700,\n",
       " 'ocean': 701,\n",
       " 'windsor': 702,\n",
       " 'cried': 703,\n",
       " 'health': 704,\n",
       " 'machine': 705,\n",
       " 'story': 706,\n",
       " 'alive': 707,\n",
       " 'outside': 708,\n",
       " 'spent': 709,\n",
       " 'sufficient': 710,\n",
       " 'hardly': 711,\n",
       " 'mentioned': 712,\n",
       " 'appear': 713,\n",
       " 'gold': 714,\n",
       " 'music': 715,\n",
       " 'madness': 716,\n",
       " 'fresh': 717,\n",
       " 'certainly': 718,\n",
       " 'yourself': 719,\n",
       " 'extreme': 720,\n",
       " 'native': 721,\n",
       " 'hung': 722,\n",
       " 'passage': 723,\n",
       " 'height': 724,\n",
       " 'pale': 725,\n",
       " 'free': 726,\n",
       " 'expected': 727,\n",
       " 'gods': 728,\n",
       " 'deserted': 729,\n",
       " 'occurred': 730,\n",
       " 'elizabeth': 731,\n",
       " 'objects': 732,\n",
       " 'extent': 733,\n",
       " 'result': 734,\n",
       " 'taking': 735,\n",
       " 'condition': 736,\n",
       " 'shore': 737,\n",
       " 'attempt': 738,\n",
       " 'covered': 739,\n",
       " 'evidently': 740,\n",
       " 'remain': 741,\n",
       " 'action': 742,\n",
       " 'vague': 743,\n",
       " \"don't\": 744,\n",
       " 'perceive': 745,\n",
       " 'immediate': 746,\n",
       " 'danger': 747,\n",
       " 'strong': 748,\n",
       " 'tomb': 749,\n",
       " 'answer': 750,\n",
       " 'mountains': 751,\n",
       " 'gentleman': 752,\n",
       " 'considered': 753,\n",
       " 'ice': 754,\n",
       " 'sort': 755,\n",
       " 'moved': 756,\n",
       " 'wood': 757,\n",
       " 'seek': 758,\n",
       " 'fall': 759,\n",
       " 'able': 760,\n",
       " 'son': 761,\n",
       " 'approached': 762,\n",
       " 'tree': 763,\n",
       " 'different': 764,\n",
       " 'boy': 765,\n",
       " 'reach': 766,\n",
       " 'sympathy': 767,\n",
       " 'english': 768,\n",
       " 'absence': 769,\n",
       " 'whilst': 770,\n",
       " 'waters': 771,\n",
       " 'number': 772,\n",
       " 'path': 773,\n",
       " 'mouth': 774,\n",
       " 'sole': 775,\n",
       " 'st': 776,\n",
       " 'courage': 777,\n",
       " 'spring': 778,\n",
       " 'discovery': 779,\n",
       " 'conversation': 780,\n",
       " 'prepared': 781,\n",
       " 'rendered': 782,\n",
       " 'except': 783,\n",
       " 'beings': 784,\n",
       " 'castle': 785,\n",
       " 'supposed': 786,\n",
       " 'greatest': 787,\n",
       " 'rain': 788,\n",
       " 'fine': 789,\n",
       " 'help': 790,\n",
       " 'melancholy': 791,\n",
       " 'progress': 792,\n",
       " 'queer': 793,\n",
       " 'peace': 794,\n",
       " 'bottom': 795,\n",
       " 'brain': 796,\n",
       " 'succeeded': 797,\n",
       " 'sufficiently': 798,\n",
       " 'village': 799,\n",
       " 'seized': 800,\n",
       " 'suffered': 801,\n",
       " 'senses': 802,\n",
       " 'creature': 803,\n",
       " 'pass': 804,\n",
       " 'step': 805,\n",
       " 'gilman': 806,\n",
       " 'rock': 807,\n",
       " 'forest': 808,\n",
       " 'island': 809,\n",
       " 'act': 810,\n",
       " 'huge': 811,\n",
       " 'creatures': 812,\n",
       " 'plain': 813,\n",
       " 'miles': 814,\n",
       " 'bear': 815,\n",
       " 'suppose': 816,\n",
       " 'dared': 817,\n",
       " 'forms': 818,\n",
       " 'besides': 819,\n",
       " 'task': 820,\n",
       " 'exceedingly': 821,\n",
       " 'foot': 822,\n",
       " 'curious': 823,\n",
       " 'fearful': 824,\n",
       " 'marble': 825,\n",
       " 'language': 826,\n",
       " 'curiosity': 827,\n",
       " 'need': 828,\n",
       " 'original': 829,\n",
       " 'talked': 830,\n",
       " 'similar': 831,\n",
       " 'smile': 832,\n",
       " 'fair': 833,\n",
       " 'persons': 834,\n",
       " 'winter': 835,\n",
       " 'frightful': 836,\n",
       " 'evidence': 837,\n",
       " 'reality': 838,\n",
       " 'intense': 839,\n",
       " 'places': 840,\n",
       " 'quickly': 841,\n",
       " 'forever': 842,\n",
       " 'rise': 843,\n",
       " 'remembered': 844,\n",
       " 'vision': 845,\n",
       " 'animal': 846,\n",
       " 'occupied': 847,\n",
       " 'perfect': 848,\n",
       " 'talk': 849,\n",
       " 'tall': 850,\n",
       " 'apartment': 851,\n",
       " 'listened': 852,\n",
       " 'ceased': 853,\n",
       " 'respect': 854,\n",
       " 'features': 855,\n",
       " 'building': 856,\n",
       " 'grey': 857,\n",
       " 'summer': 858,\n",
       " 'want': 859,\n",
       " 'breath': 860,\n",
       " 'brief': 861,\n",
       " 'watch': 862,\n",
       " 'determined': 863,\n",
       " 'journey': 864,\n",
       " 'solitude': 865,\n",
       " 'golden': 866,\n",
       " 'circumstance': 867,\n",
       " 'corner': 868,\n",
       " 'whatever': 869,\n",
       " 'concerning': 870,\n",
       " 'following': 871,\n",
       " 'fears': 872,\n",
       " 'innsmouth': 873,\n",
       " 'car': 874,\n",
       " 'flowers': 875,\n",
       " 'bent': 876,\n",
       " 'walked': 877,\n",
       " 'study': 878,\n",
       " 'arkham': 879,\n",
       " 'added': 880,\n",
       " 'obtained': 881,\n",
       " 'shewed': 882,\n",
       " 'midnight': 883,\n",
       " 'used': 884,\n",
       " 'daughter': 885,\n",
       " 'seems': 886,\n",
       " 'success': 887,\n",
       " 'spread': 888,\n",
       " 'increased': 889,\n",
       " 'dare': 890,\n",
       " 'watched': 891,\n",
       " 'glass': 892,\n",
       " 'aware': 893,\n",
       " 'remote': 894,\n",
       " 'ideas': 895,\n",
       " 'promise': 896,\n",
       " 'hard': 897,\n",
       " 'sent': 898,\n",
       " 'slowly': 899,\n",
       " 'carried': 900,\n",
       " 'leaving': 901,\n",
       " 'dupin': 902,\n",
       " 'ran': 903,\n",
       " 'meet': 904,\n",
       " 'seem': 905,\n",
       " 'key': 906,\n",
       " 'thee': 907,\n",
       " 'nose': 908,\n",
       " 'sudden': 909,\n",
       " 'familiar': 910,\n",
       " 'remarkable': 911,\n",
       " 'describe': 912,\n",
       " 'murder': 913,\n",
       " \"o'clock\": 914,\n",
       " 'rich': 915,\n",
       " 'presented': 916,\n",
       " 'week': 917,\n",
       " 'agony': 918,\n",
       " 'mystery': 919,\n",
       " 'destroyed': 920,\n",
       " 'feared': 921,\n",
       " 'evident': 922,\n",
       " 'material': 923,\n",
       " 'minute': 924,\n",
       " 'noble': 925,\n",
       " 'move': 926,\n",
       " 'learned': 927,\n",
       " 'failed': 928,\n",
       " 'enter': 929,\n",
       " 'system': 930,\n",
       " 'degrees': 931,\n",
       " 'genius': 932,\n",
       " 'disease': 933,\n",
       " 'mighty': 934,\n",
       " 'slept': 935,\n",
       " 'farther': 936,\n",
       " 'glance': 937,\n",
       " 'afterward': 938,\n",
       " 'faces': 939,\n",
       " 'eight': 940,\n",
       " 'opinion': 941,\n",
       " 'king': 942,\n",
       " 'horizon': 943,\n",
       " 'seven': 944,\n",
       " 'behold': 945,\n",
       " 'carefully': 946,\n",
       " 'afternoon': 947,\n",
       " 'relief': 948,\n",
       " 'quiet': 949,\n",
       " 'weight': 950,\n",
       " 'actually': 951,\n",
       " 'probably': 952,\n",
       " 'storm': 953,\n",
       " 'pocket': 954,\n",
       " 'gazed': 955,\n",
       " 'situation': 956,\n",
       " 'dying': 957,\n",
       " 'notice': 958,\n",
       " 'utter': 959,\n",
       " 'forced': 960,\n",
       " 'hidden': 961,\n",
       " 'unable': 962,\n",
       " 'marked': 963,\n",
       " 'ones': 964,\n",
       " 'departed': 965,\n",
       " 'piece': 966,\n",
       " 'distinct': 967,\n",
       " 'unusual': 968,\n",
       " 'powers': 969,\n",
       " 'imagine': 970,\n",
       " 'feeble': 971,\n",
       " 'possession': 972,\n",
       " 'believed': 973,\n",
       " 'visited': 974,\n",
       " 'woods': 975,\n",
       " 'physical': 976,\n",
       " 'particular': 977,\n",
       " 'search': 978,\n",
       " 'bodies': 979,\n",
       " 'sentiment': 980,\n",
       " 'fled': 981,\n",
       " 'shut': 982,\n",
       " 'gigantic': 983,\n",
       " 'amidst': 984,\n",
       " 'spirits': 985,\n",
       " 'burst': 986,\n",
       " 'despite': 987,\n",
       " 'endeavoured': 988,\n",
       " 'bitter': 989,\n",
       " 'crowd': 990,\n",
       " 'fever': 991,\n",
       " 'reply': 992,\n",
       " 'image': 993,\n",
       " 'brother': 994,\n",
       " 'clouds': 995,\n",
       " 'write': 996,\n",
       " 'size': 997,\n",
       " 'example': 998,\n",
       " 'ghastly': 999,\n",
       " 'proved': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25943/25943 [00:00<00:00, 162582.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# create an embedding matrix for the words we have in the dataset\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = glove_embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = len(word_index) + 1, 300\n",
    "output_shape = 3 # no of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple LSTM with glove embeddings and two dense layers\n",
    "def define_model(input_shape, output_shape, BiDir=False, no_of_units=100):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_shape[0],input_shape[1],weights=[embedding_matrix],input_length=max_len,\n",
    "                         trainable=False))\n",
    "    model.add(SpatialDropout1D(0.3))\n",
    "    if BiDir:\n",
    "        model.add(Bidirectional(LSTM(no_of_units, dropout=0.3, recurrent_dropout=0.3))) \n",
    "    else:\n",
    "        model.add(LSTM(no_of_units, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(output_shape))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "def train_model(model, xtrain, ytrain, xval, yval, batch_size, save_file_name):\n",
    "    # Save best model and earlystop calback\n",
    "    saveBestModel = ModelCheckpoint(save_file_name +'.hdf5', monitor='val_acc', verbose=0, save_best_only=True, \n",
    "                                save_weights_only=False, mode='auto', period=1)\n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "    # Fit the model with early stopping callback\n",
    "    \n",
    "    \n",
    "    model.fit(xtrain, y=ytrain, batch_size=batch_size, epochs=100,verbose=1, \n",
    "              validation_data=(xvalid, yvalid), callbacks=[saveBestModel,earlystop])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,xtest, ytest):\n",
    "    score, acc = model.evaluate(xtest, ytest)\n",
    "    return score, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, \n",
    "                          patience=5, verbose=0, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "[09:45:22] WARNING `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "# Save best model\n",
    "saveBestModel = ModelCheckpoint('best_weight_model.hdf5', monitor='val_acc', verbose=0, save_best_only=True, \n",
    "                                save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 25s 1ms/sample - loss: 1.0380 - val_loss: 0.9267\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 18s 1ms/sample - loss: 0.9173 - val_loss: 0.8560\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 19s 1ms/sample - loss: 0.8575 - val_loss: 0.7961\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 19s 1ms/sample - loss: 0.8242 - val_loss: 0.7835\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 18s 1ms/sample - loss: 0.8035 - val_loss: 0.7213\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - 15s 848us/sample - loss: 0.7799 - val_loss: 0.7037\n",
      "Epoch 7/100\n",
      "17621/17621 [==============================] - 17s 980us/sample - loss: 0.7643 - val_loss: 0.6910\n",
      "Epoch 8/100\n",
      "17621/17621 [==============================] - 19s 1ms/sample - loss: 0.7354 - val_loss: 0.6641\n",
      "Epoch 9/100\n",
      "17621/17621 [==============================] - 18s 1ms/sample - loss: 0.7243 - val_loss: 0.6594\n",
      "Epoch 10/100\n",
      "17621/17621 [==============================] - 16s 919us/sample - loss: 0.7123 - val_loss: 0.6464\n",
      "Epoch 11/100\n",
      "17621/17621 [==============================] - 21s 1ms/sample - loss: 0.6892 - val_loss: 0.6498\n",
      "Epoch 12/100\n",
      "17621/17621 [==============================] - 16s 897us/sample - loss: 0.6716 - val_loss: 0.6192\n",
      "Epoch 13/100\n",
      "17621/17621 [==============================] - 19s 1ms/sample - loss: 0.6521 - val_loss: 0.6102\n",
      "Epoch 14/100\n",
      "17621/17621 [==============================] - 17s 962us/sample - loss: 0.6413 - val_loss: 0.6185\n",
      "Epoch 15/100\n",
      "17621/17621 [==============================] - 16s 899us/sample - loss: 0.6244 - val_loss: 0.5989\n",
      "Epoch 16/100\n",
      "17621/17621 [==============================] - 18s 1ms/sample - loss: 0.6051 - val_loss: 0.5823\n",
      "Epoch 17/100\n",
      "17621/17621 [==============================] - 18s 1ms/sample - loss: 0.5947 - val_loss: 0.5921\n",
      "Epoch 18/100\n",
      "17621/17621 [==============================] - 16s 933us/sample - loss: 0.5757 - val_loss: 0.5701\n",
      "Epoch 19/100\n",
      "17621/17621 [==============================] - 17s 938us/sample - loss: 0.5628 - val_loss: 0.5639\n",
      "Epoch 20/100\n",
      "17621/17621 [==============================] - 18s 1ms/sample - loss: 0.5588 - val_loss: 0.5666\n",
      "Epoch 21/100\n",
      "17621/17621 [==============================] - 18s 1ms/sample - loss: 0.5381 - val_loss: 0.5450\n",
      "Epoch 22/100\n",
      "17621/17621 [==============================] - 19s 1ms/sample - loss: 0.5230 - val_loss: 0.5710\n",
      "Epoch 23/100\n",
      "17621/17621 [==============================] - 16s 929us/sample - loss: 0.5081 - val_loss: 0.5415\n",
      "Epoch 24/100\n",
      "17621/17621 [==============================] - 18s 995us/sample - loss: 0.5046 - val_loss: 0.5460\n",
      "Epoch 25/100\n",
      "17621/17621 [==============================] - 17s 962us/sample - loss: 0.4898 - val_loss: 0.5600\n",
      "Epoch 26/100\n",
      "17621/17621 [==============================] - 18s 1ms/sample - loss: 0.4806 - val_loss: 0.5349\n",
      "Epoch 27/100\n",
      "17621/17621 [==============================] - 16s 891us/sample - loss: 0.4694 - val_loss: 0.5345\n",
      "Epoch 28/100\n",
      "17621/17621 [==============================] - 18s 1ms/sample - loss: 0.4677 - val_loss: 0.5268\n",
      "Epoch 29/100\n",
      "17621/17621 [==============================] - 17s 966us/sample - loss: 0.4631 - val_loss: 0.5281\n",
      "Epoch 30/100\n",
      "17621/17621 [==============================] - 17s 958us/sample - loss: 0.4440 - val_loss: 0.5277\n",
      "Epoch 31/100\n",
      "17621/17621 [==============================] - 16s 905us/sample - loss: 0.4368 - val_loss: 0.5213\n",
      "Epoch 32/100\n",
      "17621/17621 [==============================] - 17s 941us/sample - loss: 0.4213 - val_loss: 0.5304\n",
      "Epoch 33/100\n",
      "17621/17621 [==============================] - 17s 982us/sample - loss: 0.4158 - val_loss: 0.5171\n",
      "Epoch 34/100\n",
      "17621/17621 [==============================] - 15s 856us/sample - loss: 0.4178 - val_loss: 0.5259\n",
      "Epoch 35/100\n",
      "17621/17621 [==============================] - 15s 857us/sample - loss: 0.4077 - val_loss: 0.5369\n",
      "Epoch 36/100\n",
      "17621/17621 [==============================] - 19s 1ms/sample - loss: 0.3918 - val_loss: 0.5312\n",
      "Epoch 37/100\n",
      "17621/17621 [==============================] - 18s 1ms/sample - loss: 0.3899 - val_loss: 0.5383TA: 2s - loss: \n",
      "Epoch 38/100\n",
      "17621/17621 [==============================] - 15s 880us/sample - loss: 0.3864 - val_loss: 0.5181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efe7422a588>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), \n",
    "          callbacks=[saveBestModel,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-294b46d02d69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not iterable"
     ]
    }
   ],
   "source": [
    "for key in model.history:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(xvalid_pad, yvalid_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.0379848306359407,\n",
       "  0.9173327061227634,\n",
       "  0.8574646276957087,\n",
       "  0.8242216144833403,\n",
       "  0.8034976589768342,\n",
       "  0.7799073702820476,\n",
       "  0.7643006349028013,\n",
       "  0.7353509851186921,\n",
       "  0.724269477996076,\n",
       "  0.7123113883474576,\n",
       "  0.689246386480713,\n",
       "  0.6715588240785568,\n",
       "  0.6521351950629048,\n",
       "  0.6413079424665096,\n",
       "  0.6244352102502914,\n",
       "  0.6051454433862552,\n",
       "  0.5946527099265704,\n",
       "  0.5757192616653215,\n",
       "  0.5628070246550236,\n",
       "  0.5587710691569957,\n",
       "  0.5380761694552293,\n",
       "  0.522983833891222,\n",
       "  0.5080660740874978,\n",
       "  0.5046122314274281,\n",
       "  0.4898167773831764,\n",
       "  0.48062349479671074,\n",
       "  0.4693717915579786,\n",
       "  0.4676621284270948,\n",
       "  0.4630531273914597,\n",
       "  0.4440211820843257,\n",
       "  0.4368489836108758,\n",
       "  0.42134973746911264,\n",
       "  0.4158481401933335,\n",
       "  0.41776179673350916,\n",
       "  0.4076818985519179,\n",
       "  0.39176644071717587,\n",
       "  0.38989092371979417,\n",
       "  0.3863737351233014],\n",
       " 'val_loss': [0.9266805878333344,\n",
       "  0.8560298296477383,\n",
       "  0.796139147722441,\n",
       "  0.7834595330401997,\n",
       "  0.7212868661023257,\n",
       "  0.7037076699843324,\n",
       "  0.691045728596774,\n",
       "  0.6640818589676145,\n",
       "  0.6593640252445521,\n",
       "  0.646377971515714,\n",
       "  0.6497797788833329,\n",
       "  0.6191788144691242,\n",
       "  0.610161953001636,\n",
       "  0.6185189153127699,\n",
       "  0.5989051635345716,\n",
       "  0.5822682619947214,\n",
       "  0.5921229411437879,\n",
       "  0.5701052461264691,\n",
       "  0.5638944241194487,\n",
       "  0.5666282005280835,\n",
       "  0.5449772189781298,\n",
       "  0.5710008820790923,\n",
       "  0.5414863936869433,\n",
       "  0.545973109882382,\n",
       "  0.5600290076238263,\n",
       "  0.5349147120705664,\n",
       "  0.5344525494663173,\n",
       "  0.5268420584964071,\n",
       "  0.5280656777436449,\n",
       "  0.5276811628224779,\n",
       "  0.5213090100984895,\n",
       "  0.5303718114654182,\n",
       "  0.5170594178315202,\n",
       "  0.5258778611291295,\n",
       "  0.5369149176166055,\n",
       "  0.5311677525308939,\n",
       "  0.5383202095075574,\n",
       "  0.5181032423466535]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "One question could be: why do i use so much dropout? \n",
    "Well, fit the model with no or little dropout \n",
    "and you will that it starts to overfit :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        pyplot.subplot(111)\n",
    "        pyplot.title(\"Cross Entropy Loss\")\n",
    "        pyplot.plot(histories[\"loss\"], color=\"blue\", label=\"train\")\n",
    "        pyplot.plot(histories[\"val_loss\"], color=\"orange\", label=\"test\")\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_diagnostics(model.history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Bi-Directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model(input_shape, output_shape,BiDir=True, no_of_units=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 103s 6ms/sample - loss: 1.0070 - val_loss: 0.9010\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 78s 4ms/sample - loss: 0.8752 - val_loss: 0.8077\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 76s 4ms/sample - loss: 0.8252 - val_loss: 0.7349\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 78s 4ms/sample - loss: 0.7988 - val_loss: 0.7332\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 73s 4ms/sample - loss: 0.7837 - val_loss: 0.7149\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - 79s 4ms/sample - loss: 0.7537 - val_loss: 0.6988\n",
      "Epoch 7/100\n",
      "17621/17621 [==============================] - 80s 5ms/sample - loss: 0.7430 - val_loss: 0.6935\n",
      "Epoch 8/100\n",
      "17621/17621 [==============================] - 79s 4ms/sample - loss: 0.7151 - val_loss: 0.6646\n",
      "Epoch 9/100\n",
      "17621/17621 [==============================] - 77s 4ms/sample - loss: 0.6907 - val_loss: 0.6627\n",
      "Epoch 10/100\n",
      "17621/17621 [==============================] - 76s 4ms/sample - loss: 0.6741 - val_loss: 0.6586\n",
      "Epoch 11/100\n",
      "17621/17621 [==============================] - 73s 4ms/sample - loss: 0.6495 - val_loss: 0.6388\n",
      "Epoch 12/100\n",
      "17621/17621 [==============================] - 72s 4ms/sample - loss: 0.6251 - val_loss: 0.6104\n",
      "Epoch 13/100\n",
      "17621/17621 [==============================] - 76s 4ms/sample - loss: 0.5917 - val_loss: 0.5898\n",
      "Epoch 14/100\n",
      "17621/17621 [==============================] - 72s 4ms/sample - loss: 0.5760 - val_loss: 0.5745\n",
      "Epoch 15/100\n",
      "17621/17621 [==============================] - 72s 4ms/sample - loss: 0.5496 - val_loss: 0.5740\n",
      "Epoch 16/100\n",
      "17621/17621 [==============================] - 76s 4ms/sample - loss: 0.5233 - val_loss: 0.5684\n",
      "Epoch 17/100\n",
      "17621/17621 [==============================] - 84s 5ms/sample - loss: 0.5116 - val_loss: 0.5806\n",
      "Epoch 18/100\n",
      "17621/17621 [==============================] - 73s 4ms/sample - loss: 0.5010 - val_loss: 0.5716\n",
      "Epoch 19/100\n",
      "17621/17621 [==============================] - 80s 5ms/sample - loss: 0.4715 - val_loss: 0.5558\n",
      "Epoch 20/100\n",
      "17621/17621 [==============================] - 79s 4ms/sample - loss: 0.4561 - val_loss: 0.5591\n",
      "Epoch 21/100\n",
      "17621/17621 [==============================] - 87s 5ms/sample - loss: 0.4281 - val_loss: 0.5418\n",
      "Epoch 22/100\n",
      "17621/17621 [==============================] - 78s 4ms/sample - loss: 0.4215 - val_loss: 0.5488\n",
      "Epoch 23/100\n",
      "17621/17621 [==============================] - 80s 5ms/sample - loss: 0.4035 - val_loss: 0.5420\n",
      "Epoch 24/100\n",
      "17621/17621 [==============================] - 78s 4ms/sample - loss: 0.3878 - val_loss: 0.5395\n",
      "Epoch 25/100\n",
      "17621/17621 [==============================] - 81s 5ms/sample - loss: 0.3805 - val_loss: 0.5375\n",
      "Epoch 26/100\n",
      "17621/17621 [==============================] - 83s 5ms/sample - loss: 0.3658 - val_loss: 0.5607\n",
      "Epoch 27/100\n",
      "17621/17621 [==============================] - 79s 4ms/sample - loss: 0.3510 - val_loss: 0.5458\n",
      "Epoch 28/100\n",
      "17621/17621 [==============================] - 84s 5ms/sample - loss: 0.3297 - val_loss: 0.5687\n",
      "Epoch 29/100\n",
      "17621/17621 [==============================] - 82s 5ms/sample - loss: 0.3218 - val_loss: 0.5622\n",
      "Epoch 30/100\n",
      "17621/17621 [==============================] - 83s 5ms/sample - loss: 0.3112 - val_loss: 0.5649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efdb02ae4e0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), \n",
    "          callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_diagnostics(model.history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU with glove embeddings and two dense layers\n",
    "def define_model_GRU(input_shape, output_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_shape[0],input_shape[1],weights=[embedding_matrix],input_length=max_len,\n",
    "                         trainable=False))\n",
    "    model.add(SpatialDropout1D(0.3))\n",
    "    model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "    model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3))\n",
    "    \n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(output_shape))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model_GRU(input_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 73s 4ms/sample - loss: 1.0624 - val_loss: 0.9609\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 78s 4ms/sample - loss: 0.9639 - val_loss: 0.8712\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 72s 4ms/sample - loss: 0.9136 - val_loss: 0.8190\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 72s 4ms/sample - loss: 0.8694 - val_loss: 0.7841\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 73s 4ms/sample - loss: 0.8456 - val_loss: 0.7430\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - 72s 4ms/sample - loss: 0.8249 - val_loss: 0.7273\n",
      "Epoch 7/100\n",
      "17621/17621 [==============================] - 66s 4ms/sample - loss: 0.8095 - val_loss: 0.7082\n",
      "Epoch 8/100\n",
      "17621/17621 [==============================] - 69s 4ms/sample - loss: 0.7944 - val_loss: 0.6992\n",
      "Epoch 9/100\n",
      "17621/17621 [==============================] - 70s 4ms/sample - loss: 0.7626 - val_loss: 0.6958\n",
      "Epoch 10/100\n",
      "17621/17621 [==============================] - 76s 4ms/sample - loss: 0.7541 - val_loss: 0.6568\n",
      "Epoch 11/100\n",
      "17621/17621 [==============================] - 68s 4ms/sample - loss: 0.7365 - val_loss: 0.6590\n",
      "Epoch 12/100\n",
      "17621/17621 [==============================] - 66s 4ms/sample - loss: 0.7203 - val_loss: 0.6184\n",
      "Epoch 13/100\n",
      "17621/17621 [==============================] - 66s 4ms/sample - loss: 0.6972 - val_loss: 0.6119\n",
      "Epoch 14/100\n",
      "17621/17621 [==============================] - 70s 4ms/sample - loss: 0.6848 - val_loss: 0.6559\n",
      "Epoch 15/100\n",
      "17621/17621 [==============================] - 65s 4ms/sample - loss: 0.6759 - val_loss: 0.5875\n",
      "Epoch 16/100\n",
      "17621/17621 [==============================] - 65s 4ms/sample - loss: 0.6515 - val_loss: 0.5812\n",
      "Epoch 17/100\n",
      "17621/17621 [==============================] - 65s 4ms/sample - loss: 0.6385 - val_loss: 0.5763\n",
      "Epoch 18/100\n",
      "17621/17621 [==============================] - 66s 4ms/sample - loss: 0.6291 - val_loss: 0.5703\n",
      "Epoch 19/100\n",
      "17621/17621 [==============================] - 67s 4ms/sample - loss: 0.6159 - val_loss: 0.5648\n",
      "Epoch 20/100\n",
      "17621/17621 [==============================] - 65s 4ms/sample - loss: 0.6151 - val_loss: 0.5761\n",
      "Epoch 21/100\n",
      "17621/17621 [==============================] - 67s 4ms/sample - loss: 0.5880 - val_loss: 0.5513\n",
      "Epoch 22/100\n",
      "17621/17621 [==============================] - 67s 4ms/sample - loss: 0.5792 - val_loss: 0.5658\n",
      "Epoch 23/100\n",
      "17621/17621 [==============================] - 68s 4ms/sample - loss: 0.5759 - val_loss: 0.5611\n",
      "Epoch 24/100\n",
      "17621/17621 [==============================] - 70s 4ms/sample - loss: 0.5614 - val_loss: 0.5385\n",
      "Epoch 25/100\n",
      "17621/17621 [==============================] - 70s 4ms/sample - loss: 0.5447 - val_loss: 0.5428\n",
      "Epoch 26/100\n",
      "17621/17621 [==============================] - 66s 4ms/sample - loss: 0.5483 - val_loss: 0.5241\n",
      "Epoch 27/100\n",
      "17621/17621 [==============================] - 66s 4ms/sample - loss: 0.5242 - val_loss: 0.5305\n",
      "Epoch 28/100\n",
      "17621/17621 [==============================] - 66s 4ms/sample - loss: 0.5242 - val_loss: 0.5428\n",
      "Epoch 29/100\n",
      "17621/17621 [==============================] - 68s 4ms/sample - loss: 0.5225 - val_loss: 0.5392\n",
      "Epoch 30/100\n",
      "17621/17621 [==============================] - 67s 4ms/sample - loss: 0.5100 - val_loss: 0.5217\n",
      "Epoch 31/100\n",
      "17621/17621 [==============================] - 68s 4ms/sample - loss: 0.4987 - val_loss: 0.5197\n",
      "Epoch 32/100\n",
      "17621/17621 [==============================] - 66s 4ms/sample - loss: 0.4890 - val_loss: 0.5224\n",
      "Epoch 33/100\n",
      "17621/17621 [==============================] - 65s 4ms/sample - loss: 0.4795 - val_loss: 0.5278\n",
      "Epoch 34/100\n",
      "17621/17621 [==============================] - 66s 4ms/sample - loss: 0.4758 - val_loss: 0.5413\n",
      "Epoch 35/100\n",
      "17621/17621 [==============================] - 90s 5ms/sample - loss: 0.4655 - val_loss: 0.5153\n",
      "Epoch 36/100\n",
      "17621/17621 [==============================] - 642s 36ms/sample - loss: 0.4520 - val_loss: 0.5153\n",
      "Epoch 37/100\n",
      "17621/17621 [==============================] - 69s 4ms/sample - loss: 0.4503 - val_loss: 0.5399\n",
      "Epoch 38/100\n",
      "17621/17621 [==============================] - 64s 4ms/sample - loss: 0.4454 - val_loss: 0.5269\n",
      "Epoch 39/100\n",
      "17621/17621 [==============================] - 66s 4ms/sample - loss: 0.4467 - val_loss: 0.5196\n",
      "Epoch 40/100\n",
      "17621/17621 [==============================] - 69s 4ms/sample - loss: 0.4348 - val_loss: 0.5165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd92d055c0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), \n",
    "          callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_diagnostics(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5153160764321122"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val_loss = np.min(model.history.history['val_loss'])\n",
    "min_val_loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The model improved from \n",
    "    LSTM: 0.5170594178315202 to\n",
    "    GRU: 0.5153160764321122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17621, 70)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70,)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_pad[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 70)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.expand_dims(xtrain_pad[10], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_enc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import sys\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"[%(asctime)s] %(levelname)s %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\", stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensembler(object):\n",
    "    def __init__(self, model_dict, num_folds=3, task_type='classification'\n",
    "                 , optimize=roc_auc_score,lower_is_better=False, \n",
    "                 save_path=None):\n",
    "        \"\"\"\n",
    "        Ensembler init function\n",
    "        :param model_dict: model dictionary, see README for its format\n",
    "        :param num_folds: the number of folds for ensembling\n",
    "        :param task_type: classification or regression\n",
    "        :param optimize: the function to optimize for, e.g. AUC, logloss, etc. Must have two arguments y_test and y_pred\n",
    "        :param lower_is_better: is lower value of optimization function better or higher\n",
    "        :param save_path: path to which model pickles will be dumped to along with generated predictions, or None\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_dict = model_dict\n",
    "        self.levels = len(self.model_dict)\n",
    "        self.num_folds = num_folds\n",
    "        self.task_type = task_type\n",
    "        self.optimize = optimize\n",
    "        self.lower_is_better = lower_is_better\n",
    "        self.save_path = save_path\n",
    "\n",
    "        self.training_data = None\n",
    "        self.test_data = None\n",
    "        self.y = None\n",
    "        self.lbl_enc = None\n",
    "        self.y_enc = None\n",
    "        self.train_prediction_dict = None\n",
    "        self.test_prediction_dict = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def fit(self, training_data, y, lentrain):\n",
    "        \"\"\"\n",
    "        :param training_data: training data in tabular format\n",
    "        :param y: binary, multi-class or regression\n",
    "        :return: chain of models to be used in prediction\n",
    "        \"\"\"\n",
    "\n",
    "        self.training_data = training_data\n",
    "        self.y = y\n",
    "\n",
    "        if self.task_type == 'classification':\n",
    "            self.num_classes = len(np.unique(self.y))\n",
    "            logger.info(\"Found %d classes\", self.num_classes)\n",
    "            self.lbl_enc = LabelEncoder()\n",
    "            self.y_enc = self.lbl_enc.fit_transform(self.y)\n",
    "            kf = StratifiedKFold(n_splits=self.num_folds)\n",
    "            train_prediction_shape = (lentrain, self.num_classes)\n",
    "        else:\n",
    "            self.num_classes = -1\n",
    "            self.y_enc = self.y\n",
    "            kf = KFold(n_splits=self.num_folds)\n",
    "            train_prediction_shape = (lentrain, 1)\n",
    "\n",
    "        self.train_prediction_dict = {}\n",
    "        for level in range(self.levels):\n",
    "            self.train_prediction_dict[level] = np.zeros(\n",
    "                (train_prediction_shape[0],\n",
    "                 train_prediction_shape[1] * len(self.model_dict[level])))\n",
    "\n",
    "        for level in range(self.levels):\n",
    "\n",
    "            if level == 0:\n",
    "                temp_train = self.training_data\n",
    "            else:\n",
    "                temp_train = self.train_prediction_dict[level - 1]\n",
    "\n",
    "            for model_num, model in enumerate(self.model_dict[level]):\n",
    "                validation_scores = []\n",
    "                foldnum = 1\n",
    "                for train_index, valid_index in kf.split(\n",
    "                    self.train_prediction_dict[0], self.y_enc):\n",
    "                    \n",
    "                    logger.info(\"Training Level %d Fold # %d. Model # %d\", \n",
    "                                level, foldnum, model_num)\n",
    "\n",
    "                    if level != 0:\n",
    "                        l_training_data = temp_train[train_index]\n",
    "                        l_validation_data = temp_train[valid_index]\n",
    "                        model.fit(l_training_data, self.y_enc[train_index])\n",
    "                    else:\n",
    "                        l0_training_data = temp_train[0][model_num]\n",
    "                        if type(l0_training_data) == list:\n",
    "                            l_training_data = [x[train_index] for x in l0_training_data]\n",
    "                            l_validation_data = [x[valid_index] for x in l0_training_data]\n",
    "                        else:\n",
    "                            l_training_data = l0_training_data[train_index]\n",
    "                            l_validation_data = l0_training_data[valid_index]\n",
    "                        model.fit(l_training_data, self.y_enc[train_index])\n",
    "\n",
    "                    logger.info(\"Predicting Level %d. Fold # %d. Model # %d\", level, foldnum, model_num)\n",
    "\n",
    "                    if self.task_type == 'classification':\n",
    "                        temp_train_predictions = model.predict_proba(l_validation_data)\n",
    "                        self.train_prediction_dict[level][valid_index,\n",
    "                        (model_num * self.num_classes):(model_num * self.num_classes) +\n",
    "                                                       self.num_classes] = temp_train_predictions\n",
    "\n",
    "                    else:\n",
    "                        temp_train_predictions = model.predict(l_validation_data)\n",
    "                        self.train_prediction_dict[level][valid_index, model_num] = temp_train_predictions\n",
    "                    validation_score = self.optimize(self.y_enc[valid_index], temp_train_predictions)\n",
    "                    validation_scores.append(validation_score)\n",
    "                    logger.info(\"Level %d. Fold # %d. Model # %d. Validation Score = %f\", level, foldnum, model_num,\n",
    "                                validation_score)\n",
    "                    foldnum += 1\n",
    "                avg_score = np.mean(validation_scores)\n",
    "                std_score = np.std(validation_scores)\n",
    "                logger.info(\"Level %d. Model # %d. Mean Score = %f. Std Dev = %f\", level, model_num,\n",
    "                            avg_score, std_score)\n",
    "\n",
    "            logger.info(\"Saving predictions for level # %d\", level)\n",
    "            train_predictions_df = pd.DataFrame(self.train_prediction_dict[level])\n",
    "            train_predictions_df.to_csv(os.path.join(self.save_path, \"train_predictions_level_\" + str(level) + \".csv\"),\n",
    "                                        index=False, header=None)\n",
    "\n",
    "        return self.train_prediction_dict\n",
    "\n",
    "    def predict(self, test_data, lentest):\n",
    "        self.test_data = test_data\n",
    "        if self.task_type == 'classification':\n",
    "            test_prediction_shape = (lentest, self.num_classes)\n",
    "        else:\n",
    "            test_prediction_shape = (lentest, 1)\n",
    "\n",
    "        self.test_prediction_dict = {}\n",
    "        for level in range(self.levels):\n",
    "            self.test_prediction_dict[level] = np.zeros((test_prediction_shape[0],\n",
    "                                                         test_prediction_shape[1] * len(self.model_dict[level])))\n",
    "        self.test_data = test_data\n",
    "        for level in range(self.levels):\n",
    "            if level == 0:\n",
    "                temp_train = self.training_data\n",
    "                temp_test = self.test_data\n",
    "            else:\n",
    "                temp_train = self.train_prediction_dict[level - 1]\n",
    "                temp_test = self.test_prediction_dict[level - 1]\n",
    "\n",
    "            for model_num, model in enumerate(self.model_dict[level]):\n",
    "\n",
    "                logger.info(\"Training Fulldata Level %d. Model # %d\", level, model_num)\n",
    "                if level == 0:\n",
    "                    model.fit(temp_train[0][model_num], self.y_enc)\n",
    "                else:\n",
    "                    model.fit(temp_train, self.y_enc)\n",
    "\n",
    "                logger.info(\"Predicting Test Level %d. Model # %d\", level, model_num)\n",
    "\n",
    "                if self.task_type == 'classification':\n",
    "                    if level == 0:\n",
    "                        temp_test_predictions = model.predict_proba(temp_test[0][model_num])\n",
    "                    else:\n",
    "                        temp_test_predictions = model.predict_proba(temp_test)\n",
    "                    self.test_prediction_dict[level][:, (model_num * self.num_classes): (model_num * self.num_classes) +\n",
    "                                                                                        self.num_classes] = temp_test_predictions\n",
    "\n",
    "                else:\n",
    "                    if level == 0:\n",
    "                        temp_test_predictions = model.predict(temp_test[0][model_num])\n",
    "                    else:\n",
    "                        temp_test_predictions = model.predict(temp_test)\n",
    "                    self.test_prediction_dict[level][:, model_num] = temp_test_predictions\n",
    "\n",
    "            test_predictions_df = pd.DataFrame(self.test_prediction_dict[level])\n",
    "            test_predictions_df.to_csv(os.path.join(self.save_path, \"test_predictions_level_\" + str(level) + \".csv\"),\n",
    "                                       index=False, header=None)\n",
    "\n",
    "        return self.test_prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the data to be used for every level of ensembling:\n",
    "train_data_dict = {0: [x_tfidf, x_ctv, x_tfidf, x_ctv], \n",
    "                   1: [xtrain_glove]}\n",
    "test_data_dict = {0: [v_tfidf, v_ctv, v_tfidf, v_ctv], \n",
    "                  1: [xvalid_glove]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {0: [LogisticRegression(), LogisticRegression(), \n",
    "                  MultinomialNB(alpha=0.1), MultinomialNB()],\n",
    "              1: [XGBClassifier(silent=True, n_estimators=120, \n",
    "                                    max_depth=7)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = Ensembler(model_dict=model_dict, num_folds=3, \n",
    "                task_type='classification',\n",
    "                optimize=multiclass_logloss, lower_is_better=True, \n",
    "                save_path='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:22] INFO Found 3 classes\n",
      "[17:24:22] INFO Training Level 0 Fold # 1. Model # 0\n",
      "[17:24:24] INFO Predicting Level 0. Fold # 1. Model # 0\n",
      "[17:24:24] INFO Level 0. Fold # 1. Model # 0. Validation Score = 0.626621\n",
      "[17:24:24] INFO Training Level 0 Fold # 2. Model # 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:26] INFO Predicting Level 0. Fold # 2. Model # 0\n",
      "[17:24:26] INFO Level 0. Fold # 2. Model # 0. Validation Score = 0.616458\n",
      "[17:24:26] INFO Training Level 0 Fold # 3. Model # 0\n",
      "[17:24:28] INFO Predicting Level 0. Fold # 3. Model # 0\n",
      "[17:24:28] INFO Level 0. Fold # 3. Model # 0. Validation Score = 0.619625\n",
      "[17:24:28] INFO Level 0. Model # 0. Mean Score = 0.620901. Std Dev = 0.004246\n",
      "[17:24:28] INFO Training Level 0 Fold # 1. Model # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:54] INFO Predicting Level 0. Fold # 1. Model # 1\n",
      "[17:24:54] INFO Level 0. Fold # 1. Model # 1. Validation Score = 0.573485\n",
      "[17:24:54] INFO Training Level 0 Fold # 2. Model # 1\n",
      "[17:25:17] INFO Predicting Level 0. Fold # 2. Model # 1\n",
      "[17:25:17] INFO Level 0. Fold # 2. Model # 1. Validation Score = 0.563451\n",
      "[17:25:17] INFO Training Level 0 Fold # 3. Model # 1\n",
      "[17:25:39] INFO Predicting Level 0. Fold # 3. Model # 1\n",
      "[17:25:39] INFO Level 0. Fold # 3. Model # 1. Validation Score = 0.567765\n",
      "[17:25:39] INFO Level 0. Model # 1. Mean Score = 0.568233. Std Dev = 0.004110\n",
      "[17:25:39] INFO Training Level 0 Fold # 1. Model # 2\n",
      "[17:25:39] INFO Predicting Level 0. Fold # 1. Model # 2\n",
      "[17:25:39] INFO Level 0. Fold # 1. Model # 2. Validation Score = 0.463292\n",
      "[17:25:39] INFO Training Level 0 Fold # 2. Model # 2\n",
      "[17:25:39] INFO Predicting Level 0. Fold # 2. Model # 2\n",
      "[17:25:39] INFO Level 0. Fold # 2. Model # 2. Validation Score = 0.456477\n",
      "[17:25:39] INFO Training Level 0 Fold # 3. Model # 2\n",
      "[17:25:39] INFO Predicting Level 0. Fold # 3. Model # 2\n",
      "[17:25:39] INFO Level 0. Fold # 3. Model # 2. Validation Score = 0.461664\n",
      "[17:25:39] INFO Level 0. Model # 2. Mean Score = 0.460478. Std Dev = 0.002906\n",
      "[17:25:39] INFO Training Level 0 Fold # 1. Model # 3\n",
      "[17:25:39] INFO Predicting Level 0. Fold # 1. Model # 3\n",
      "[17:25:39] INFO Level 0. Fold # 1. Model # 3. Validation Score = 0.472378\n",
      "[17:25:39] INFO Training Level 0 Fold # 2. Model # 3\n",
      "[17:25:39] INFO Predicting Level 0. Fold # 2. Model # 3\n",
      "[17:25:39] INFO Level 0. Fold # 2. Model # 3. Validation Score = 0.473229\n",
      "[17:25:39] INFO Training Level 0 Fold # 3. Model # 3\n",
      "[17:25:39] INFO Predicting Level 0. Fold # 3. Model # 3\n",
      "[17:25:39] INFO Level 0. Fold # 3. Model # 3. Validation Score = 0.479033\n",
      "[17:25:39] INFO Level 0. Model # 3. Mean Score = 0.474880. Std Dev = 0.002957\n",
      "[17:25:39] INFO Saving predictions for level # 0\n",
      "[17:25:40] INFO Training Level 1 Fold # 1. Model # 0\n",
      "[17:25:46] INFO Predicting Level 1. Fold # 1. Model # 0\n",
      "[17:25:46] INFO Level 1. Fold # 1. Model # 0. Validation Score = 0.485556\n",
      "[17:25:46] INFO Training Level 1 Fold # 2. Model # 0\n",
      "[17:25:48] INFO Predicting Level 1. Fold # 2. Model # 0\n",
      "[17:25:48] INFO Level 1. Fold # 2. Model # 0. Validation Score = 0.472065\n",
      "[17:25:48] INFO Training Level 1 Fold # 3. Model # 0\n",
      "[17:25:50] INFO Predicting Level 1. Fold # 3. Model # 0\n",
      "[17:25:50] INFO Level 1. Fold # 3. Model # 0. Validation Score = 0.495281\n",
      "[17:25:50] INFO Level 1. Model # 0. Mean Score = 0.484301. Std Dev = 0.009520\n",
      "[17:25:50] INFO Saving predictions for level # 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: array([[1.82507980e-01, 5.62445949e-01, 2.55046071e-01, ...,\n",
       "         1.63905894e-03, 9.78914382e-01, 1.94465590e-02],\n",
       "        [5.81491564e-01, 8.06830731e-02, 3.37825363e-01, ...,\n",
       "         9.12471891e-01, 1.32663502e-03, 8.62014740e-02],\n",
       "        [2.93323536e-01, 1.35036429e-01, 5.71640035e-01, ...,\n",
       "         1.82118284e-02, 8.72006925e-05, 9.81700971e-01],\n",
       "        ...,\n",
       "        [7.75923272e-01, 1.26977715e-01, 9.70990128e-02, ...,\n",
       "         9.86335183e-01, 1.23153067e-02, 1.34950984e-03],\n",
       "        [1.26112693e-01, 1.58593905e-01, 7.15293402e-01, ...,\n",
       "         2.91343713e-02, 3.19121725e-02, 9.38953456e-01],\n",
       "        [4.42053774e-01, 1.84822099e-01, 3.73124127e-01, ...,\n",
       "         6.30341085e-01, 2.44825189e-02, 3.45176396e-01]]),\n",
       " 1: array([[9.07164346e-03, 9.81958687e-01, 8.96969251e-03],\n",
       "        [2.18813434e-01, 1.74064073e-03, 7.79445946e-01],\n",
       "        [2.12095324e-02, 9.45792941e-04, 9.77844715e-01],\n",
       "        ...,\n",
       "        [9.91931617e-01, 1.49883714e-03, 6.56957692e-03],\n",
       "        [1.03254123e-02, 1.27766011e-02, 9.76897955e-01],\n",
       "        [7.35851884e-01, 1.84058342e-02, 2.45742291e-01]])}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens.fit(train_data_dict, y_train, lentrain=xtrain_glove.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:27:11] INFO Training Fulldata Level 0. Model # 0\n",
      "[17:27:14] INFO Predicting Test Level 0. Model # 0\n",
      "[17:27:14] INFO Training Fulldata Level 0. Model # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:27:37] INFO Predicting Test Level 0. Model # 1\n",
      "[17:27:37] INFO Training Fulldata Level 0. Model # 2\n",
      "[17:27:37] INFO Predicting Test Level 0. Model # 2\n",
      "[17:27:37] INFO Training Fulldata Level 0. Model # 3\n",
      "[17:27:37] INFO Predicting Test Level 0. Model # 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:27:37] INFO Training Fulldata Level 1. Model # 0\n",
      "[17:27:40] INFO Predicting Test Level 1. Model # 0\n"
     ]
    }
   ],
   "source": [
    "preds = ens.predict(test_data_dict, lentest=xvalid_glove.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46601874174462027"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check error:\n",
    "multiclass_logloss(y_valid, preds[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Thus, we see that ensembling improves the score by a great extent! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ensemble_clf.joblib']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(ens, 'ensemble_clf.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('ensemble_clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:33:35] INFO Training Fulldata Level 0. Model # 0\n",
      "[17:33:38] INFO Predicting Test Level 0. Model # 0\n",
      "[17:33:38] INFO Training Fulldata Level 0. Model # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:34:01] INFO Predicting Test Level 0. Model # 1\n",
      "[17:34:01] INFO Training Fulldata Level 0. Model # 2\n",
      "[17:34:01] INFO Predicting Test Level 0. Model # 2\n",
      "[17:34:01] INFO Training Fulldata Level 0. Model # 3\n",
      "[17:34:01] INFO Predicting Test Level 0. Model # 3\n",
      "[17:34:01] INFO Training Fulldata Level 1. Model # 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:34:04] INFO Predicting Test Level 1. Model # 0\n"
     ]
    }
   ],
   "source": [
    "predict = clf.predict(test_data_dict, lentest=xvalid_glove.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46601874174462027"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check error:\n",
    "multiclass_logloss(y_valid, predict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.009071643464267254</th>\n",
       "      <th>0.9819586873054504</th>\n",
       "      <th>0.008969692513346672</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218813</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.779446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021210</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.977845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.971037</td>\n",
       "      <td>0.023294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.989951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046584</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.947547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.012276</td>\n",
       "      <td>0.982712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.312612</td>\n",
       "      <td>0.015788</td>\n",
       "      <td>0.671600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.726404</td>\n",
       "      <td>0.224827</td>\n",
       "      <td>0.048769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.999714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.009071643464267254  0.9819586873054504  0.008969692513346672\n",
       "0              0.218813            0.001741              0.779446\n",
       "1              0.021210            0.000946              0.977845\n",
       "2              0.005669            0.971037              0.023294\n",
       "3              0.002966            0.007082              0.989951\n",
       "4              0.046584            0.005869              0.947547\n",
       "5              0.000066            0.999887              0.000046\n",
       "6              0.005012            0.012276              0.982712\n",
       "7              0.312612            0.015788              0.671600\n",
       "8              0.726404            0.224827              0.048769\n",
       "9              0.000260            0.000025              0.999714"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_predictions_level_1.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
